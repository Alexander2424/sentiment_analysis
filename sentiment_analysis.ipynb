{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aspect Based Sentiment Analysis\n",
    "\n",
    "_N.B. Entire notebook wall time: 3min 30s_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1\n",
    "_Perform aspect based sentiment analysis at the sentence level_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) __Parse xml training data:__\n",
    "- Import necessary packages\n",
    "- Parse into pandas data frame to be able to work with review data at the sentence level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "import nltk\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import spacy\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xml_to_df(filename):\n",
    "    # Parse xml file into pandas data frame to work with at the sentence level\n",
    "    tree = ET.parse(filename)\n",
    "    root = tree.getroot()\n",
    "    reviews = root.findall('Review')\n",
    "    df_columns = ['rid','id','text','category','predicted_category','polarity','predicted_polarity']\n",
    "    reviews_df = pd.DataFrame(columns=df_columns)\n",
    "\n",
    "    for review in reviews:\n",
    "        rid = review.get('rid')\n",
    "        sentences = review.findall('sentences/sentence')\n",
    "        for sentence in sentences:\n",
    "            id = sentence.get('id')\n",
    "            text = sentence.find('text').text\n",
    "            opinions = sentence.findall('Opinions/Opinion')\n",
    "            for opinion in opinions:\n",
    "                category = opinion.get('category')\n",
    "                polarity = opinion.get('polarity')\n",
    "                predicted_category = ''\n",
    "                predicted_polarity = ''\n",
    "                reviews_df = pd.concat([reviews_df, \n",
    "                            pd.DataFrame([[rid, id, text, category, \n",
    "                            predicted_category, polarity,predicted_polarity]],\n",
    "                            columns=df_columns)], ignore_index=True)\n",
    "    \n",
    "    return reviews_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rid</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>predicted_category</th>\n",
       "      <th>polarity</th>\n",
       "      <th>predicted_polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79</td>\n",
       "      <td>79:1</td>\n",
       "      <td>This computer is absolutely AMAZING!!!</td>\n",
       "      <td>LAPTOP#GENERAL</td>\n",
       "      <td></td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79</td>\n",
       "      <td>79:2</td>\n",
       "      <td>10 plus hours of battery...</td>\n",
       "      <td>BATTERY#OPERATION_PERFORMANCE</td>\n",
       "      <td></td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>79</td>\n",
       "      <td>79:3</td>\n",
       "      <td>super fast processor and really nice graphics ...</td>\n",
       "      <td>CPU#OPERATION_PERFORMANCE</td>\n",
       "      <td></td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>79</td>\n",
       "      <td>79:3</td>\n",
       "      <td>super fast processor and really nice graphics ...</td>\n",
       "      <td>GRAPHICS#GENERAL</td>\n",
       "      <td></td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79</td>\n",
       "      <td>79:4</td>\n",
       "      <td>and plenty of storage with 250 gb(though I wil...</td>\n",
       "      <td>HARD_DISC#DESIGN_FEATURES</td>\n",
       "      <td></td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  rid    id                                               text  \\\n",
       "0  79  79:1             This computer is absolutely AMAZING!!!   \n",
       "1  79  79:2                        10 plus hours of battery...   \n",
       "2  79  79:3  super fast processor and really nice graphics ...   \n",
       "3  79  79:3  super fast processor and really nice graphics ...   \n",
       "4  79  79:4  and plenty of storage with 250 gb(though I wil...   \n",
       "\n",
       "                        category predicted_category  polarity  \\\n",
       "0                 LAPTOP#GENERAL                     positive   \n",
       "1  BATTERY#OPERATION_PERFORMANCE                     positive   \n",
       "2      CPU#OPERATION_PERFORMANCE                     positive   \n",
       "3               GRAPHICS#GENERAL                     positive   \n",
       "4      HARD_DISC#DESIGN_FEATURES                     positive   \n",
       "\n",
       "  predicted_polarity  \n",
       "0                     \n",
       "1                     \n",
       "2                     \n",
       "3                     \n",
       "4                     "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_reviews_df = xml_to_df(filename='Laptops_Train_p1.xml')\n",
    "train_reviews_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) __Text processing__\n",
    "- Create copy of original data frame, populate with processed text\n",
    "- tokenise words\n",
    "- remove stop words\n",
    "- remove punctuation\n",
    "- stem words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a copy of original data frame to populate with processed text\n",
    "processed_df = train_reviews_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenise(text):\n",
    "    # Tokenising sentences\n",
    "    tokenised_text = [word_tokenize(sentence.lower()) for sentence in text]\n",
    "    return tokenised_text\n",
    "\n",
    "def remove_stopwords(tokenised_text):\n",
    "    # Remove stop words\n",
    "    tokens = []\n",
    "    for token in tokenised_text:\n",
    "        if token not in stopwords.words('english'):\n",
    "            tokens.append(token)\n",
    "    return tokens\n",
    "\n",
    "def remove_non_alpha(tokenised_text):\n",
    "    # Remove punctuation\n",
    "    alpha_tokens = []\n",
    "    for token in tokenised_text:\n",
    "        if token.isalpha():\n",
    "            alpha_tokens.append(token)\n",
    "    return alpha_tokens\n",
    "\n",
    "def stem(tokenised_text):\n",
    "    # Stem tokenised text\n",
    "    snow_stemmer = SnowballStemmer(language='english')\n",
    "    stem_tokens = []\n",
    "    for token in tokenised_text:\n",
    "        stem_tokens.append(snow_stemmer.stem(token))\n",
    "  \n",
    "    stemmed_text = \" \".join(stem_tokens)\n",
    "    return stemmed_text\n",
    "\n",
    "def preprocess(tokenised_text):\n",
    "  # output processed text\n",
    "  pp_data = []\n",
    "  for sentence in tokenised_text:\n",
    "    pp_text = remove_stopwords(sentence)\n",
    "    pp_text = remove_non_alpha(pp_text)\n",
    "    pp_text = stem(pp_text)\n",
    "    pp_data.append(pp_text)\n",
    "  return pp_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rid</th>\n",
       "      <th>id</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>category</th>\n",
       "      <th>predicted_category</th>\n",
       "      <th>polarity</th>\n",
       "      <th>predicted_polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79</td>\n",
       "      <td>79:1</td>\n",
       "      <td>comput absolut amaz</td>\n",
       "      <td>LAPTOP#GENERAL</td>\n",
       "      <td></td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79</td>\n",
       "      <td>79:2</td>\n",
       "      <td>plus hour batteri</td>\n",
       "      <td>BATTERY#OPERATION_PERFORMANCE</td>\n",
       "      <td></td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>79</td>\n",
       "      <td>79:3</td>\n",
       "      <td>super fast processor realli nice graphic card</td>\n",
       "      <td>CPU#OPERATION_PERFORMANCE</td>\n",
       "      <td></td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>79</td>\n",
       "      <td>79:3</td>\n",
       "      <td>super fast processor realli nice graphic card</td>\n",
       "      <td>GRAPHICS#GENERAL</td>\n",
       "      <td></td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79</td>\n",
       "      <td>79:4</td>\n",
       "      <td>plenti storag gb though upgrad ram</td>\n",
       "      <td>HARD_DISC#DESIGN_FEATURES</td>\n",
       "      <td></td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  rid    id                                 processed_text  \\\n",
       "0  79  79:1                            comput absolut amaz   \n",
       "1  79  79:2                              plus hour batteri   \n",
       "2  79  79:3  super fast processor realli nice graphic card   \n",
       "3  79  79:3  super fast processor realli nice graphic card   \n",
       "4  79  79:4             plenti storag gb though upgrad ram   \n",
       "\n",
       "                        category predicted_category  polarity  \\\n",
       "0                 LAPTOP#GENERAL                     positive   \n",
       "1  BATTERY#OPERATION_PERFORMANCE                     positive   \n",
       "2      CPU#OPERATION_PERFORMANCE                     positive   \n",
       "3               GRAPHICS#GENERAL                     positive   \n",
       "4      HARD_DISC#DESIGN_FEATURES                     positive   \n",
       "\n",
       "  predicted_polarity  \n",
       "0                     \n",
       "1                     \n",
       "2                     \n",
       "3                     \n",
       "4                     "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df['text'] = preprocess(tokenise(train_reviews_df['text']))\n",
    "processed_df = processed_df.rename(columns={\"text\": \"processed_text\"})\n",
    "processed_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) __Identify entity-attribute (E#A) pairs__\n",
    "- Topic classification task: ___Logistic Regression___\n",
    "    - Logistic Regression performs much better on training data category classification than Naive Bayes\n",
    "    - Logistic Regression ($83$% accuracy) vs. Naive Bayes ($67$% accuracy)\n",
    "- Identify the entity for each sentence\n",
    "- Identify the attribute for each sentence\n",
    "- Combine the Entity and Attribute predictions to produce E#A pair\n",
    "- Sentences with multiple categories identified and the probabilities for each label computed to inform predictions\n",
    "- Test LR model predictions on training data with overall accuracy score\n",
    "    - Classification report produced for test data\n",
    "- Output predictions in new prediction column in dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Set of functions below used throughout section 3. Functions used again when making predictions and reports on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def e_a_predict(features, X_train_counts, model, threshold):\n",
    "    # Returns the next most likely topic if a given sentence has multiple categories\n",
    "    # if probability for next most likely topic is > threshold, else return most likely topic.\n",
    "\n",
    "    N = len(features)\n",
    "    tmp = 0\n",
    "    repeat = 0\n",
    "    predictions = np.zeros(N)\n",
    "    for i in range(N):\n",
    "        if features[i] != tmp:\n",
    "            predictions[i] = model.predict(X_train_counts[i,:])\n",
    "            repeat = 0\n",
    "        else:\n",
    "            repeat += 1\n",
    "            arr = model.predict_proba(X_train_counts[i,:])\n",
    "            sorted_index = np.argsort(arr)[0]\n",
    "            if arr[0][sorted_index[-repeat-1]] > threshold/repeat:\n",
    "                predictions[i] = float(sorted_index[-repeat-1])\n",
    "            else:\n",
    "                predictions[i] = model.predict(X_train_counts[i,:])\n",
    "            # handle part 2 error where >8 opinions for single review gives index error\n",
    "            if repeat > 7:\n",
    "                repeat -= 1\n",
    "        tmp = features[i]\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "def sorted_predictions(df):\n",
    "    # Aligns predictions with matching labels for sentences that have multiple opinions.\n",
    "    # e.g., ground truth for sentence id=1: LAPTOP#GENERAL, LAPTOP#BATTERY_PERFORMANCE\n",
    "    # predictions for sentence id=1 pre-alignment: LAPTOP#BATTERY_PERFORMANCE, LAPTOP#GENERAL\n",
    "    # predictions post-alignment: LAPTOP#GENERAL, LAPTOP#BATTERY_PERFORMANCE\n",
    "\n",
    "    N = len(df['category'])\n",
    "    labels_dict = {}\n",
    "    predictions_dict = {}\n",
    "    sorted_predictions = []\n",
    "    i = 0\n",
    "    tmp = 0\n",
    "\n",
    "    for id in df['id'].unique():\n",
    "        labels_dict[id] = list(df.query(f\"id == '{id}'\")['category'])\n",
    "        predictions_dict[id] = list(df.query(f\"id == '{id}'\")['predicted_category'])\n",
    "\n",
    "    for key in labels_dict.keys():\n",
    "        for value in labels_dict[key]:\n",
    "            if value in predictions_dict[key]:\n",
    "\n",
    "                idx = labels_dict[key].index(value) # obtain label index for matching label & prediction for given sentence id\n",
    "                idx2 = predictions_dict[key].index(value) # obtain prediction index for matching label & prediction for given sentence id\n",
    "\n",
    "                tmp = predictions_dict[key][idx]\n",
    "\n",
    "                predictions_dict[key][idx] = value # re-order predictions so that they align with ground truth for given id\n",
    "                predictions_dict[key][idx2] = tmp # swap changed values in predictions list for sentence id\n",
    "    \n",
    "    for values in predictions_dict.values():\n",
    "        for value in values:\n",
    "            sorted_predictions.append(value)\n",
    "\n",
    "    return list(sorted_predictions)\n",
    "\n",
    "def numerical_entity_attributes(df):\n",
    "    # Numerical representation of predicted categories is required for accuracy\n",
    "    # and classification report. Function converts category predictions to\n",
    "    # numerical representation\n",
    "\n",
    "    category, predicted_category = df['category'], df['predicted_category']\n",
    "\n",
    "    e_a_list = category.unique().tolist()\n",
    "    i = 0\n",
    "    e_a_label_dict = {}\n",
    "    for e_a in e_a_list:\n",
    "        e_a_label_dict[e_a] = i\n",
    "        i += 1\n",
    "\n",
    "    e_a_labels = []\n",
    "    for i in range(len(category)):\n",
    "        e_a_labels.append(e_a_label_dict[category[i]])\n",
    "\n",
    "    e_a_predictions = []\n",
    "    for i in range(len(category)):\n",
    "        if predicted_category[i] in e_a_list:\n",
    "            e_a_predictions.append(e_a_label_dict[predicted_category[i]])\n",
    "        else:\n",
    "            e_a_predictions.append(99) # predicted E#A pair not in ground truth set of E#A pairs\n",
    "\n",
    "    e_a_labels = np.array(e_a_labels, dtype=int)\n",
    "    e_a_predictions = np.array(e_a_predictions, dtype=int)\n",
    "    e_a_list.append('N/A')\n",
    "\n",
    "    return e_a_labels, e_a_predictions, e_a_list, e_a_label_dict\n",
    "\n",
    "def reverse_dict(my_dict):\n",
    "    # Reverses the keys and values in a dictionary, useful for several later steps\n",
    "    reversed_dict = {}\n",
    "    for key, value in my_dict.items(): \n",
    "        reversed_dict[value] = key \n",
    "    return reversed_dict\n",
    "\n",
    "def numerical_labels(df, label_name, new_column_name=str()):\n",
    "    # Convert ground truth word labels for entities or attributes to numerical representation\n",
    "    labels_list = df[label_name].unique().tolist()\n",
    "    df[new_column_name] = ''\n",
    "    i = 0\n",
    "    labels_dict = {} # Will use this to convert numerical class predictions back to attributes\n",
    "    for label in labels_list:\n",
    "        df.loc[df[label_name] == label, new_column_name] = i\n",
    "        labels_dict[i] = label\n",
    "        i += 1\n",
    "    \n",
    "    return labels_list, labels_dict\n",
    "\n",
    "def convert_numerical_predictions(num_predictions, label_dict):\n",
    "    # Convert numerical predictions back to words\n",
    "    num_predictions = num_predictions.tolist()\n",
    "    word_predictions = []\n",
    "\n",
    "    for pred in num_predictions:\n",
    "        word_predictions.append(label_dict[pred])\n",
    "    \n",
    "    return word_predictions\n",
    "\n",
    "def combine_entity_attributes(df, entity_pred, attrib_pred):\n",
    "    # Combine Entity and Attribute predictions to create E#A pair predictions\n",
    "    # Sort E#A pair category predictions\n",
    "    combined_list = []\n",
    "    for i in range(len(df['category'])):\n",
    "        e_a_pair = entity_pred[i] + \"#\" + attrib_pred[i]\n",
    "        combined_list.append(e_a_pair)\n",
    "    \n",
    "    return combined_list\n",
    "\n",
    "def overall_accuracy_absa(df):\n",
    "    # Returns an overall accuracy score as a % of the instances where both the\n",
    "    # category predictions AND the sentiment predicitons were correct.\n",
    "    N = len(df['category'])\n",
    "    correct_count = 0\n",
    "    for i in range(N):\n",
    "        if df['category'][i] == df['predicted_category'][i] and df['polarity'][i] == df['predicted_polarity'][i]:\n",
    "            correct_count += 1\n",
    "    \n",
    "    accuracy = (correct_count/N)*100\n",
    "    output = f\"Overall accuracy for correct category and sentiment predictions: {accuracy:.0f}%\"\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Creating training features for entity and attribute classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = processed_df['processed_text']\n",
    "# Using counts to extract features from text\n",
    "count_vectorizer = CountVectorizer()\n",
    "X_train_counts = count_vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Training topic classifier first for entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate entities from categories and add to new column\n",
    "processed_df['entity'] = [entity.split('#')[0] for entity in processed_df['category']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label entities\n",
    "entities_list, entity_label_dict = numerical_labels(processed_df, 'entity', 'entity_label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training set for entity classification\n",
    "Y_entity_train = processed_df['entity_label']\n",
    "Y_entity_train = np.array(Y_entity_train, dtype=int)\n",
    "\n",
    "# Train the entity classification Logistic Regression model\n",
    "entity_count_lr = LogisticRegression()\n",
    "entity_count_lr.fit(X_train_counts, Y_entity_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set entity predicitons accuracy score: 84%\n"
     ]
    }
   ],
   "source": [
    "# Testing entity prediction on training data... overfitting likely\n",
    "Y_entity_train_pred = e_a_predict(X_train,X_train_counts,model=entity_count_lr,threshold=0.1) # threshold hyperparameter tuned on training data\n",
    "entity_train_accuracy = accuracy_score(Y_entity_train, Y_entity_train_pred)\n",
    "\n",
    "print(f\"Training set entity predicitons accuracy score: {entity_train_accuracy*100:.0f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert entity predictions from numbers back to words\n",
    "entity_predictions = convert_numerical_predictions(Y_entity_train_pred, entity_label_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Training topic classifier for attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate attributes from categories and add to new column\n",
    "processed_df['attribute'] = [attribute.split('#')[1] for attribute in processed_df['category']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label attributes\n",
    "attributes_list, attribute_label_dict = numerical_labels(processed_df, 'attribute', 'attribute_label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training set for attribute classification\n",
    "Y_attrib_train = processed_df['attribute_label']\n",
    "Y_attrib_train = np.array(Y_attrib_train, dtype=int)\n",
    "\n",
    "# Train the attribute classification Logistic Regression model\n",
    "attrib_count_lr = LogisticRegression()\n",
    "attrib_count_lr.fit(X_train_counts, Y_attrib_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set attribute predictions accuracy score: 71%\n"
     ]
    }
   ],
   "source": [
    "# Testing attribute prediction on training data... overfitting likely\n",
    "Y_attrib_train_pred = e_a_predict(X_train,X_train_counts,model=attrib_count_lr,threshold=0.1) # threshold hyperparameter tuned on training data\n",
    "attrib_train_accuracy = accuracy_score(Y_attrib_train, Y_attrib_train_pred)\n",
    "\n",
    "print(f\"Training set attribute predictions accuracy score: {attrib_train_accuracy*100:.0f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert attribute predictions from numbers back to words\n",
    "attribute_predictions = convert_numerical_predictions(Y_attrib_train_pred, attribute_label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine Entity and Attribute predictions to create E#A pair predictions\n",
    "processed_df['predicted_category'] = combine_entity_attributes(processed_df, entity_predictions, attribute_predictions)\n",
    "\n",
    "# Sort Entity and Attribute predictions for more representative accuracy score (see example in function comments)\n",
    "processed_df['predicted_category'] = sorted_predictions(processed_df)\n",
    "train_reviews_df['predicted_category'] = sorted_predictions(processed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set category predictions accuracy score: 83%\n"
     ]
    }
   ],
   "source": [
    "e_a_labels, e_a_predictions, e_a_list, e_a_label_dict  = numerical_entity_attributes(processed_df)\n",
    "category_train_accuracy = accuracy_score(e_a_labels, e_a_predictions)\n",
    "\n",
    "print(f\"Training set category predictions accuracy score: {category_train_accuracy*100:.0f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now that Entity and Attribute classifiers have been trained and the predictions have been converted back to words, the dataframes will be populated with the predicted E#A pairs for the training set.\n",
    "- Combined entity and attribute pair predictions on the training data:\n",
    "    - E#A accuracy $=83$%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rid</th>\n",
       "      <th>id</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>entity</th>\n",
       "      <th>entity_label</th>\n",
       "      <th>attribute</th>\n",
       "      <th>attribute_label</th>\n",
       "      <th>category</th>\n",
       "      <th>predicted_category</th>\n",
       "      <th>polarity</th>\n",
       "      <th>predicted_polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79</td>\n",
       "      <td>79:1</td>\n",
       "      <td>comput absolut amaz</td>\n",
       "      <td>LAPTOP</td>\n",
       "      <td>0</td>\n",
       "      <td>GENERAL</td>\n",
       "      <td>0</td>\n",
       "      <td>LAPTOP#GENERAL</td>\n",
       "      <td>LAPTOP#GENERAL</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79</td>\n",
       "      <td>79:2</td>\n",
       "      <td>plus hour batteri</td>\n",
       "      <td>BATTERY</td>\n",
       "      <td>1</td>\n",
       "      <td>OPERATION_PERFORMANCE</td>\n",
       "      <td>1</td>\n",
       "      <td>BATTERY#OPERATION_PERFORMANCE</td>\n",
       "      <td>BATTERY#OPERATION_PERFORMANCE</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>79</td>\n",
       "      <td>79:3</td>\n",
       "      <td>super fast processor realli nice graphic card</td>\n",
       "      <td>CPU</td>\n",
       "      <td>2</td>\n",
       "      <td>OPERATION_PERFORMANCE</td>\n",
       "      <td>1</td>\n",
       "      <td>CPU#OPERATION_PERFORMANCE</td>\n",
       "      <td>CPU#OPERATION_PERFORMANCE</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>79</td>\n",
       "      <td>79:3</td>\n",
       "      <td>super fast processor realli nice graphic card</td>\n",
       "      <td>GRAPHICS</td>\n",
       "      <td>3</td>\n",
       "      <td>GENERAL</td>\n",
       "      <td>0</td>\n",
       "      <td>GRAPHICS#GENERAL</td>\n",
       "      <td>GRAPHICS#GENERAL</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79</td>\n",
       "      <td>79:4</td>\n",
       "      <td>plenti storag gb though upgrad ram</td>\n",
       "      <td>HARD_DISC</td>\n",
       "      <td>4</td>\n",
       "      <td>DESIGN_FEATURES</td>\n",
       "      <td>2</td>\n",
       "      <td>HARD_DISC#DESIGN_FEATURES</td>\n",
       "      <td>HARD_DISC#DESIGN_FEATURES</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  rid    id                                 processed_text     entity  \\\n",
       "0  79  79:1                            comput absolut amaz     LAPTOP   \n",
       "1  79  79:2                              plus hour batteri    BATTERY   \n",
       "2  79  79:3  super fast processor realli nice graphic card        CPU   \n",
       "3  79  79:3  super fast processor realli nice graphic card   GRAPHICS   \n",
       "4  79  79:4             plenti storag gb though upgrad ram  HARD_DISC   \n",
       "\n",
       "  entity_label              attribute attribute_label  \\\n",
       "0            0                GENERAL               0   \n",
       "1            1  OPERATION_PERFORMANCE               1   \n",
       "2            2  OPERATION_PERFORMANCE               1   \n",
       "3            3                GENERAL               0   \n",
       "4            4        DESIGN_FEATURES               2   \n",
       "\n",
       "                        category             predicted_category  polarity  \\\n",
       "0                 LAPTOP#GENERAL                 LAPTOP#GENERAL  positive   \n",
       "1  BATTERY#OPERATION_PERFORMANCE  BATTERY#OPERATION_PERFORMANCE  positive   \n",
       "2      CPU#OPERATION_PERFORMANCE      CPU#OPERATION_PERFORMANCE  positive   \n",
       "3               GRAPHICS#GENERAL               GRAPHICS#GENERAL  positive   \n",
       "4      HARD_DISC#DESIGN_FEATURES      HARD_DISC#DESIGN_FEATURES  positive   \n",
       "\n",
       "  predicted_polarity  \n",
       "0                     \n",
       "1                     \n",
       "2                     \n",
       "3                     \n",
       "4                     "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reorder columns\n",
    "reorder_columns = ['rid','id','processed_text','entity','entity_label',\n",
    "                  'attribute','attribute_label','category','predicted_category',\n",
    "                  'polarity','predicted_polarity']\n",
    "processed_df = processed_df.reindex(columns=reorder_columns)\n",
    "processed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rid</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>predicted_category</th>\n",
       "      <th>polarity</th>\n",
       "      <th>predicted_polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79</td>\n",
       "      <td>79:1</td>\n",
       "      <td>This computer is absolutely AMAZING!!!</td>\n",
       "      <td>LAPTOP#GENERAL</td>\n",
       "      <td>LAPTOP#GENERAL</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79</td>\n",
       "      <td>79:2</td>\n",
       "      <td>10 plus hours of battery...</td>\n",
       "      <td>BATTERY#OPERATION_PERFORMANCE</td>\n",
       "      <td>BATTERY#OPERATION_PERFORMANCE</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>79</td>\n",
       "      <td>79:3</td>\n",
       "      <td>super fast processor and really nice graphics ...</td>\n",
       "      <td>CPU#OPERATION_PERFORMANCE</td>\n",
       "      <td>CPU#OPERATION_PERFORMANCE</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>79</td>\n",
       "      <td>79:3</td>\n",
       "      <td>super fast processor and really nice graphics ...</td>\n",
       "      <td>GRAPHICS#GENERAL</td>\n",
       "      <td>GRAPHICS#GENERAL</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79</td>\n",
       "      <td>79:4</td>\n",
       "      <td>and plenty of storage with 250 gb(though I wil...</td>\n",
       "      <td>HARD_DISC#DESIGN_FEATURES</td>\n",
       "      <td>HARD_DISC#DESIGN_FEATURES</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  rid    id                                               text  \\\n",
       "0  79  79:1             This computer is absolutely AMAZING!!!   \n",
       "1  79  79:2                        10 plus hours of battery...   \n",
       "2  79  79:3  super fast processor and really nice graphics ...   \n",
       "3  79  79:3  super fast processor and really nice graphics ...   \n",
       "4  79  79:4  and plenty of storage with 250 gb(though I wil...   \n",
       "\n",
       "                        category             predicted_category  polarity  \\\n",
       "0                 LAPTOP#GENERAL                 LAPTOP#GENERAL  positive   \n",
       "1  BATTERY#OPERATION_PERFORMANCE  BATTERY#OPERATION_PERFORMANCE  positive   \n",
       "2      CPU#OPERATION_PERFORMANCE      CPU#OPERATION_PERFORMANCE  positive   \n",
       "3               GRAPHICS#GENERAL               GRAPHICS#GENERAL  positive   \n",
       "4      HARD_DISC#DESIGN_FEATURES      HARD_DISC#DESIGN_FEATURES  positive   \n",
       "\n",
       "  predicted_polarity  \n",
       "0                     \n",
       "1                     \n",
       "2                     \n",
       "3                     \n",
       "4                     "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_reviews_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) __Perform sentiment analysis on the sentence for each identified E#A pair__\n",
    "- Sentiment classification task: __Logistic Regression__\n",
    "    - Logistic Regression selected for sentiment classification. Logistic Regression model performed marginally better than Naive Bayes on the training data ($84$% vs $83$%).\n",
    "- Output predictions in prediction column in dataframe\n",
    "- Test model predictions on training data with overall accuracy score\n",
    "- multiclass classification: (positive, neutral or negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Set of functions below used throughout section 4. Functions used again when making predictions and reports on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_text(text):\n",
    "    # Split input sentence/review by by coordinating conjunctions e.g., ['and','but','because']\n",
    "    # If no CC in sentence, then split by punctuation\n",
    "    # Each element (part of sentence) can then be assigned to different categories for the same sentence id, \n",
    "    # based on cosine similarity measure\n",
    "\n",
    "    split_input = []\n",
    "    for sentence in text:\n",
    "        sentence = sentence.lower()\n",
    "        sent_tag = nltk.pos_tag(nltk.word_tokenize(sentence))\n",
    "\n",
    "        split_words = []\n",
    "        pos_tags = ['CC']\n",
    "        for elem in sent_tag:\n",
    "            if elem[1] in pos_tags:\n",
    "                split_words.append(elem[0])\n",
    "        \n",
    "        punctuation = [',',';','-']\n",
    "        cc_in_flag = False\n",
    "        for elem in sent_tag:\n",
    "            if elem[1] in pos_tags:\n",
    "                cc_in_flag = True\n",
    "        \n",
    "        if not cc_in_flag:\n",
    "            for elem in sent_tag:\n",
    "                if elem[1] in punctuation:\n",
    "                    split_words.append(elem[0])\n",
    "\n",
    "        result = []\n",
    "        if split_words:\n",
    "            for index, word in enumerate(split_words):\n",
    "                result.append(sentence.split(split_words[index])[0])\n",
    "                if len(sentence.split(split_words[index]))>1:\n",
    "                    sentence = sentence.split(split_words[index])[1]\n",
    "            result.append(sentence)\n",
    "        else:\n",
    "            result.append(sentence)\n",
    "\n",
    "        result = [item.strip() for item in result]\n",
    "        result = [item for item in result if item]\n",
    "        split_input.append(result)\n",
    "        \n",
    "    return split_input\n",
    "\n",
    "def filter_sentiment_input(text, cat):\n",
    "    # Keep only most relevant element in sentence list to determine polarity for category\n",
    "    # Measuring similarity between nouns in element of sentence and category (E#A) pair\n",
    "    # Less expensive (more efficient) similarity calculation using only nouns rather than all words in part of sentence\n",
    "    reduced_text = []\n",
    "    for index, row in enumerate(text):\n",
    "        n = len(row)\n",
    "        tmp_dict = {}\n",
    "        for i in range(n):\n",
    "            cat_list = re.split('_|#', cat.loc[index])\n",
    "            cat_list = [item.title() if item != 'OS' else item for item in cat_list]\n",
    "            category = nlp(' '.join(cat_list))\n",
    "\n",
    "            sent_tag = nltk.pos_tag(nltk.word_tokenize(row[i].lower()))\n",
    "            noun_pos = ['NN','NNS','NNP']\n",
    "            noun_list = [elem[0] for elem in sent_tag if elem[1] in noun_pos]\n",
    "            noun_text = nlp(' '.join(noun_list))\n",
    "\n",
    "            tmp_dict[row[i]] = category.similarity(noun_text)\n",
    "\n",
    "        reduced_text.append(max(tmp_dict, key = tmp_dict.get))\n",
    "\n",
    "    return reduced_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label sentiments\n",
    "sentiments_list, polarity_label_dict = numerical_labels(processed_df, 'polarity', 'polarity_label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training set for sentiment classification\n",
    "Y_sentiment_train = processed_df['polarity_label']\n",
    "Y_sentiment_train = np.array(Y_sentiment_train, dtype=int)\n",
    "\n",
    "# Train the attribute classification Naive Bayes model\n",
    "sentiment_count_lr = LogisticRegression()\n",
    "sentiment_count_lr.fit(X_train_counts, Y_sentiment_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Creating new dataframe to assist with sentiment predictions for each category:\n",
    "    - Split sentences on coordinating conjunctions (CC) e.g., [\"and\", \"but\", ...]\n",
    "    - Each category that needs sentiment predicting now has a list of strings as possible input features to determine sentiment\n",
    "    - Instead of using entire sentence to predict polarity for a specific category, use spacy Cosine similarity function to determine which elements of list (parts of sentence) to keep to determine sentiment using already trained model. \n",
    "    - If sentence has no coordinating conjunctions, then split by punctuation in the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_processed_df = train_reviews_df.copy()\n",
    "sentiment_processed_df['text'] = split_input_text(train_reviews_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N.B. cell takes ~30secs to run\n",
    "sentiment_processed_df['text'] = filter_sentiment_input(sentiment_processed_df['text'], sentiment_processed_df['predicted_category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Can see below the effect of filtering the sentence to only keep the part deemed most similar to the predicted category for aspect based sentiment classification\n",
    "- For same sentence id 273:9, only using part of the sentence to determine sentiment for specific predicted category\n",
    "    - Original sentence: _\"It's more expensive but well worth it in the long run.\"_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rid</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>predicted_category</th>\n",
       "      <th>polarity</th>\n",
       "      <th>predicted_polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>273</td>\n",
       "      <td>273:9</td>\n",
       "      <td>it's more expensive</td>\n",
       "      <td>LAPTOP#PRICE</td>\n",
       "      <td>LAPTOP#PRICE</td>\n",
       "      <td>negative</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>273</td>\n",
       "      <td>273:9</td>\n",
       "      <td>well worth it in the long run.</td>\n",
       "      <td>LAPTOP#GENERAL</td>\n",
       "      <td>LAPTOP#GENERAL</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rid     id                            text        category  \\\n",
       "85  273  273:9             it's more expensive    LAPTOP#PRICE   \n",
       "86  273  273:9  well worth it in the long run.  LAPTOP#GENERAL   \n",
       "\n",
       "   predicted_category  polarity predicted_polarity  \n",
       "85       LAPTOP#PRICE  negative                     \n",
       "86     LAPTOP#GENERAL  positive                     "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_processed_df.query(\"id == '273:9'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input for sentiment prediction on training set\n",
    "sentiment_processed_df['processed_text'] = preprocess(tokenise(sentiment_processed_df['text']))\n",
    "\n",
    "X_sentiment_input = sentiment_processed_df['processed_text']\n",
    "X_sentiment_input = count_vectorizer.transform(X_sentiment_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set sentiment prediction accuracy score: 84%\n"
     ]
    }
   ],
   "source": [
    "# Testing sentiment prediction on training data... overfitting likely\n",
    "Y_sentiment_train_pred = sentiment_count_lr.predict(X_sentiment_input)\n",
    "\n",
    "sentiment_train_accuracy = accuracy_score(Y_sentiment_train, Y_sentiment_train_pred)\n",
    "print(f\"Training set sentiment prediction accuracy score: {sentiment_train_accuracy*100:.0f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr = classification_report(Y_sentiment_train, Y_sentiment_train_pred, target_names=sentiments_list)\n",
    "# print(cr)\n",
    "# Note that only 188 neutral training examples out of 2909... will be difficult to learn properties of neutral input features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert sentiment predictions from numbers back to words\n",
    "sentiment_predictions = convert_numerical_predictions(Y_sentiment_train_pred, polarity_label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rid</th>\n",
       "      <th>id</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>entity</th>\n",
       "      <th>entity_label</th>\n",
       "      <th>attribute</th>\n",
       "      <th>attribute_label</th>\n",
       "      <th>category</th>\n",
       "      <th>predicted_category</th>\n",
       "      <th>polarity</th>\n",
       "      <th>polarity_label</th>\n",
       "      <th>predicted_polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79</td>\n",
       "      <td>79:1</td>\n",
       "      <td>comput absolut amaz</td>\n",
       "      <td>LAPTOP</td>\n",
       "      <td>0</td>\n",
       "      <td>GENERAL</td>\n",
       "      <td>0</td>\n",
       "      <td>LAPTOP#GENERAL</td>\n",
       "      <td>LAPTOP#GENERAL</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79</td>\n",
       "      <td>79:2</td>\n",
       "      <td>plus hour batteri</td>\n",
       "      <td>BATTERY</td>\n",
       "      <td>1</td>\n",
       "      <td>OPERATION_PERFORMANCE</td>\n",
       "      <td>1</td>\n",
       "      <td>BATTERY#OPERATION_PERFORMANCE</td>\n",
       "      <td>BATTERY#OPERATION_PERFORMANCE</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>79</td>\n",
       "      <td>79:3</td>\n",
       "      <td>super fast processor realli nice graphic card</td>\n",
       "      <td>CPU</td>\n",
       "      <td>2</td>\n",
       "      <td>OPERATION_PERFORMANCE</td>\n",
       "      <td>1</td>\n",
       "      <td>CPU#OPERATION_PERFORMANCE</td>\n",
       "      <td>CPU#OPERATION_PERFORMANCE</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>79</td>\n",
       "      <td>79:3</td>\n",
       "      <td>super fast processor realli nice graphic card</td>\n",
       "      <td>GRAPHICS</td>\n",
       "      <td>3</td>\n",
       "      <td>GENERAL</td>\n",
       "      <td>0</td>\n",
       "      <td>GRAPHICS#GENERAL</td>\n",
       "      <td>GRAPHICS#GENERAL</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79</td>\n",
       "      <td>79:4</td>\n",
       "      <td>plenti storag gb though upgrad ram</td>\n",
       "      <td>HARD_DISC</td>\n",
       "      <td>4</td>\n",
       "      <td>DESIGN_FEATURES</td>\n",
       "      <td>2</td>\n",
       "      <td>HARD_DISC#DESIGN_FEATURES</td>\n",
       "      <td>HARD_DISC#DESIGN_FEATURES</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  rid    id                                 processed_text     entity  \\\n",
       "0  79  79:1                            comput absolut amaz     LAPTOP   \n",
       "1  79  79:2                              plus hour batteri    BATTERY   \n",
       "2  79  79:3  super fast processor realli nice graphic card        CPU   \n",
       "3  79  79:3  super fast processor realli nice graphic card   GRAPHICS   \n",
       "4  79  79:4             plenti storag gb though upgrad ram  HARD_DISC   \n",
       "\n",
       "  entity_label              attribute attribute_label  \\\n",
       "0            0                GENERAL               0   \n",
       "1            1  OPERATION_PERFORMANCE               1   \n",
       "2            2  OPERATION_PERFORMANCE               1   \n",
       "3            3                GENERAL               0   \n",
       "4            4        DESIGN_FEATURES               2   \n",
       "\n",
       "                        category             predicted_category  polarity  \\\n",
       "0                 LAPTOP#GENERAL                 LAPTOP#GENERAL  positive   \n",
       "1  BATTERY#OPERATION_PERFORMANCE  BATTERY#OPERATION_PERFORMANCE  positive   \n",
       "2      CPU#OPERATION_PERFORMANCE      CPU#OPERATION_PERFORMANCE  positive   \n",
       "3               GRAPHICS#GENERAL               GRAPHICS#GENERAL  positive   \n",
       "4      HARD_DISC#DESIGN_FEATURES      HARD_DISC#DESIGN_FEATURES  positive   \n",
       "\n",
       "  polarity_label predicted_polarity  \n",
       "0              0           positive  \n",
       "1              0           negative  \n",
       "2              0           positive  \n",
       "3              0           positive  \n",
       "4              0           positive  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df['predicted_polarity'] = sentiment_predictions\n",
    "reorder_columns = ['rid','id','processed_text','entity','entity_label',\n",
    "                  'attribute','attribute_label','category','predicted_category',\n",
    "                  'polarity','polarity_label','predicted_polarity']\n",
    "processed_df = processed_df.reindex(columns=reorder_columns)\n",
    "processed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rid</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>predicted_category</th>\n",
       "      <th>polarity</th>\n",
       "      <th>predicted_polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79</td>\n",
       "      <td>79:1</td>\n",
       "      <td>This computer is absolutely AMAZING!!!</td>\n",
       "      <td>LAPTOP#GENERAL</td>\n",
       "      <td>LAPTOP#GENERAL</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79</td>\n",
       "      <td>79:2</td>\n",
       "      <td>10 plus hours of battery...</td>\n",
       "      <td>BATTERY#OPERATION_PERFORMANCE</td>\n",
       "      <td>BATTERY#OPERATION_PERFORMANCE</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>79</td>\n",
       "      <td>79:3</td>\n",
       "      <td>super fast processor and really nice graphics ...</td>\n",
       "      <td>CPU#OPERATION_PERFORMANCE</td>\n",
       "      <td>CPU#OPERATION_PERFORMANCE</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>79</td>\n",
       "      <td>79:3</td>\n",
       "      <td>super fast processor and really nice graphics ...</td>\n",
       "      <td>GRAPHICS#GENERAL</td>\n",
       "      <td>GRAPHICS#GENERAL</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79</td>\n",
       "      <td>79:4</td>\n",
       "      <td>and plenty of storage with 250 gb(though I wil...</td>\n",
       "      <td>HARD_DISC#DESIGN_FEATURES</td>\n",
       "      <td>HARD_DISC#DESIGN_FEATURES</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  rid    id                                               text  \\\n",
       "0  79  79:1             This computer is absolutely AMAZING!!!   \n",
       "1  79  79:2                        10 plus hours of battery...   \n",
       "2  79  79:3  super fast processor and really nice graphics ...   \n",
       "3  79  79:3  super fast processor and really nice graphics ...   \n",
       "4  79  79:4  and plenty of storage with 250 gb(though I wil...   \n",
       "\n",
       "                        category             predicted_category  polarity  \\\n",
       "0                 LAPTOP#GENERAL                 LAPTOP#GENERAL  positive   \n",
       "1  BATTERY#OPERATION_PERFORMANCE  BATTERY#OPERATION_PERFORMANCE  positive   \n",
       "2      CPU#OPERATION_PERFORMANCE      CPU#OPERATION_PERFORMANCE  positive   \n",
       "3               GRAPHICS#GENERAL               GRAPHICS#GENERAL  positive   \n",
       "4      HARD_DISC#DESIGN_FEATURES      HARD_DISC#DESIGN_FEATURES  positive   \n",
       "\n",
       "  predicted_polarity  \n",
       "0           positive  \n",
       "1           negative  \n",
       "2           positive  \n",
       "3           positive  \n",
       "4           positive  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_reviews_df['predicted_polarity'] = sentiment_predictions\n",
    "train_reviews_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) __Evaluate accuracy__\n",
    "    - Measure E#A pair prediction and sentiment prediction test set accuracy\n",
    "    - Using classification report with accuracy measures discussed in Week 5 lecture slides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Classification report for E#A predictions on test set data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rid</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>predicted_category</th>\n",
       "      <th>polarity</th>\n",
       "      <th>predicted_polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B0074703CM_108_ANONYMOUS</td>\n",
       "      <td>B0074703CM_108_ANONYMOUS:0</td>\n",
       "      <td>Well, my first apple computer and I am impressed.</td>\n",
       "      <td>LAPTOP#GENERAL</td>\n",
       "      <td></td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B0074703CM_108_ANONYMOUS</td>\n",
       "      <td>B0074703CM_108_ANONYMOUS:1</td>\n",
       "      <td>Works well, fast and no reboots.</td>\n",
       "      <td>LAPTOP#OPERATION_PERFORMANCE</td>\n",
       "      <td></td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B0074703CM_108_ANONYMOUS</td>\n",
       "      <td>B0074703CM_108_ANONYMOUS:4</td>\n",
       "      <td>Glad I did so far.</td>\n",
       "      <td>COMPANY#GENERAL</td>\n",
       "      <td></td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        rid                          id  \\\n",
       "0  B0074703CM_108_ANONYMOUS  B0074703CM_108_ANONYMOUS:0   \n",
       "1  B0074703CM_108_ANONYMOUS  B0074703CM_108_ANONYMOUS:1   \n",
       "2  B0074703CM_108_ANONYMOUS  B0074703CM_108_ANONYMOUS:4   \n",
       "\n",
       "                                                text  \\\n",
       "0  Well, my first apple computer and I am impressed.   \n",
       "1                   Works well, fast and no reboots.   \n",
       "2                                 Glad I did so far.   \n",
       "\n",
       "                       category predicted_category  polarity  \\\n",
       "0                LAPTOP#GENERAL                     positive   \n",
       "1  LAPTOP#OPERATION_PERFORMANCE                     positive   \n",
       "2               COMPANY#GENERAL                     positive   \n",
       "\n",
       "  predicted_polarity  \n",
       "0                     \n",
       "1                     \n",
       "2                     "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_reviews_df = xml_to_df(filename='Laptops_Test_p1_gold.xml')\n",
    "test_processed_df = test_reviews_df.copy()\n",
    "test_reviews_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pre-processing test set text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-process test set text\n",
    "test_processed_df['text'] = preprocess(tokenise(test_reviews_df['text']))\n",
    "\n",
    "# Obtain test set input features\n",
    "X_test = test_processed_df['text']\n",
    "X_test_counts = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Make Entity predictions using trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict test set entities\n",
    "Y_entity_test_pred = e_a_predict(X_test,X_test_counts,model=entity_count_lr,threshold=0.1) # threshold hyperparameter tuned on training data\n",
    "\n",
    "# Convert entity predictions back to words\n",
    "test_entity_predictions = convert_numerical_predictions(Y_entity_test_pred, entity_label_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Make Attribute predictions using trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict test set attributes\n",
    "Y_attrib_test_pred = e_a_predict(X_test,X_test_counts,model=attrib_count_lr,threshold=0.1) # threshold hyperparameter tuned on training data\n",
    "\n",
    "# Convert attribute predictions back to words\n",
    "test_attribute_predictions = convert_numerical_predictions(Y_attrib_test_pred, attribute_label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine Entity and Attribute predictions to create E#A pair predictions\n",
    "test_processed_df['predicted_category'] = combine_entity_attributes(test_processed_df, test_entity_predictions, test_attribute_predictions)\n",
    "\n",
    "# Sort Entity and Attribute predictions for more representative accuracy score (see example in function comments)\n",
    "test_processed_df['predicted_category'] = sorted_predictions(test_processed_df)\n",
    "test_reviews_df['predicted_category'] = sorted_predictions(test_processed_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Produce Classification report for E#A pair predictions on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted E#A Category Classification Report (Test Set):\n",
      "\n",
      "                                    precision    recall  f1-score   support\n",
      "\n",
      "                    LAPTOP#GENERAL       0.49      0.84      0.62       158\n",
      "      LAPTOP#OPERATION_PERFORMANCE       0.54      0.67      0.60        70\n",
      "                   COMPANY#GENERAL       0.83      0.13      0.23        38\n",
      "                  LAPTOP#USABILITY       0.39      0.33      0.36        46\n",
      "              LAPTOP#MISCELLANEOUS       0.36      0.26      0.31        34\n",
      "            LAPTOP#DESIGN_FEATURES       0.59      0.55      0.57        73\n",
      "                LAPTOP#PORTABILITY       0.67      0.33      0.44         6\n",
      "     BATTERY#OPERATION_PERFORMANCE       0.68      0.68      0.68        19\n",
      "                      LAPTOP#PRICE       0.81      0.52      0.63        25\n",
      "         HARD_DISC#DESIGN_FEATURES       0.50      0.15      0.24        13\n",
      "                   DISPLAY#QUALITY       0.55      0.30      0.39        20\n",
      "                    LAPTOP#QUALITY       0.33      0.72      0.45        47\n",
      "              POWER_SUPPLY#GENERAL       0.00      0.00      0.00         1\n",
      "        MULTIMEDIA_DEVICES#QUALITY       0.75      0.43      0.55         7\n",
      "                  SHIPPING#QUALITY       0.00      0.00      0.00         1\n",
      "    OPTICAL_DRIVES#DESIGN_FEATURES       0.00      0.00      0.00         2\n",
      "        MULTIMEDIA_DEVICES#GENERAL       0.33      0.33      0.33         3\n",
      "                      OS#USABILITY       0.60      0.20      0.30        15\n",
      "                        OS#GENERAL       0.17      0.11      0.13         9\n",
      "             MOUSE#DESIGN_FEATURES       0.50      0.50      0.50         4\n",
      "          KEYBOARD#DESIGN_FEATURES       0.20      0.29      0.24         7\n",
      "           DISPLAY#DESIGN_FEATURES       0.33      0.15      0.21        13\n",
      "                   MOUSE#USABILITY       0.60      0.23      0.33        13\n",
      "                 HARD_DISC#GENERAL       0.00      0.00      0.00         2\n",
      "                   DISPLAY#GENERAL       0.00      0.00      0.00         4\n",
      "                   SUPPORT#QUALITY       0.53      0.24      0.33        33\n",
      "            MEMORY#DESIGN_FEATURES       0.67      0.25      0.36         8\n",
      "         CPU#OPERATION_PERFORMANCE       0.00      0.00      0.00         2\n",
      "               LAPTOP#CONNECTIVITY       1.00      0.15      0.27        13\n",
      "                KEYBOARD#USABILITY       0.75      0.50      0.60         6\n",
      "                SOFTWARE#USABILITY       0.67      0.29      0.40         7\n",
      "MULTIMEDIA_DEVICES#DESIGN_FEATURES       0.00      0.00      0.00         6\n",
      "               CPU#DESIGN_FEATURES       0.00      0.00      0.00         3\n",
      "          GRAPHICS#DESIGN_FEATURES       0.00      0.00      0.00         2\n",
      "                  KEYBOARD#QUALITY       0.33      0.14      0.20         7\n",
      "FANS_COOLING#OPERATION_PERFORMANCE       0.00      0.00      0.00         2\n",
      "     DISPLAY#OPERATION_PERFORMANCE       0.20      0.12      0.15         8\n",
      "                 DISPLAY#USABILITY       1.00      0.20      0.33         5\n",
      "    KEYBOARD#OPERATION_PERFORMANCE       0.50      0.11      0.18         9\n",
      "                OS#DESIGN_FEATURES       0.00      0.00      0.00         5\n",
      "            OPTICAL_DRIVES#GENERAL       0.00      0.00      0.00         1\n",
      "      POWER_SUPPLY#DESIGN_FEATURES       0.00      0.00      0.00         1\n",
      "                  OS#MISCELLANEOUS       0.00      0.00      0.00         2\n",
      "                   BATTERY#QUALITY       0.25      0.20      0.22         5\n",
      "                     SUPPORT#PRICE       0.00      0.00      0.00         2\n",
      "               MOTHERBOARD#QUALITY       0.00      0.00      0.00         2\n",
      "                  KEYBOARD#GENERAL       0.17      0.50      0.25         2\n",
      "                     MOUSE#GENERAL       0.00      0.00      0.00         4\n",
      "                  SOFTWARE#GENERAL       1.00      0.20      0.33         5\n",
      "       MOUSE#OPERATION_PERFORMANCE       0.20      0.33      0.25         3\n",
      "                  HARDWARE#QUALITY       0.00      0.00      0.00         4\n",
      "                 CPU#MISCELLANEOUS       0.00      0.00      0.00         1\n",
      "            GRAPHICS#MISCELLANEOUS       0.00      0.00      0.00         1\n",
      "      MULTIMEDIA_DEVICES#USABILITY       0.00      0.00      0.00         1\n",
      "   HARD_DISC#OPERATION_PERFORMANCE       0.00      0.00      0.00         5\n",
      "    SOFTWARE#OPERATION_PERFORMANCE       0.33      0.50      0.40         2\n",
      "                        OS#QUALITY       0.50      0.50      0.50         2\n",
      "       PORTS#OPERATION_PERFORMANCE       0.00      0.00      0.00         2\n",
      "          SOFTWARE#DESIGN_FEATURES       0.00      0.00      0.00         1\n",
      "                  WARRANTY#GENERAL       0.00      0.00      0.00         1\n",
      "           BATTERY#DESIGN_FEATURES       0.00      0.00      0.00         1\n",
      "                       CPU#GENERAL       0.00      0.00      0.00         1\n",
      "          OS#OPERATION_PERFORMANCE       0.33      1.00      0.50         1\n",
      "                     MOUSE#QUALITY       0.50      0.50      0.50         2\n",
      "                 HARD_DISC#QUALITY       0.00      0.00      0.00         1\n",
      "                    SOFTWARE#PRICE       0.00      0.00      0.00         1\n",
      "                  SOFTWARE#QUALITY       0.00      0.00      0.00         1\n",
      "                               N/A       0.00      0.00      0.00         0\n",
      "\n",
      "                          accuracy                           0.46       801\n",
      "                         macro avg       0.28      0.20      0.20       801\n",
      "                      weighted avg       0.49      0.46      0.42       801\n",
      "\n"
     ]
    }
   ],
   "source": [
    "e_a_labels, e_a_predictions, e_a_list, e_a_label_dict = numerical_entity_attributes(test_processed_df)\n",
    "\n",
    "# Note target_names=e_a_list displays E#A categories as text form rather than numerical representation\n",
    "cr = classification_report(e_a_labels, e_a_predictions, target_names=e_a_list)\n",
    "print(\"Predicted E#A Category Classification Report (Test Set):\\n\")\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Classification report for sentiment predictions on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reversing the polarity label dict to faciliatate test set polarity conversion to numerical labels.\n",
    "reversed_polarity_label_dict = reverse_dict(polarity_label_dict)\n",
    "\n",
    "Y_sentiment_test_labels = [reversed_polarity_label_dict[test_processed_df['polarity'][i]] for i in range(len(test_processed_df['polarity']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing filtered input for aspect based sentiment predictions on test set\n",
    "test_sentiment_prep_df = test_reviews_df.copy()\n",
    "test_sentiment_prep_df['text'] = split_input_text(test_reviews_df['text'])\n",
    "\n",
    "test_sentiment_prep_df['processed_text'] = preprocess(tokenise(filter_sentiment_input(test_sentiment_prep_df['text'], test_sentiment_prep_df['predicted_category'])))\n",
    "X_test_sentiment_input = count_vectorizer.transform(test_sentiment_prep_df['processed_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Sentiment Classification Report (Test Set):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.72      0.75      0.74       481\n",
      "    negative       0.54      0.57      0.55       274\n",
      "     neutral       0.20      0.04      0.07        46\n",
      "\n",
      "    accuracy                           0.65       801\n",
      "   macro avg       0.49      0.46      0.45       801\n",
      "weighted avg       0.63      0.65      0.64       801\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classifcation report for sentiment precitions on test data\n",
    "Y_sentiment_test_pred = sentiment_count_lr.predict(X_test_sentiment_input)\n",
    "Y_sentiment_test_labels = np.array([Y_sentiment_test_labels]).reshape(801,)\n",
    "\n",
    "cr = classification_report(Y_sentiment_test_labels, Y_sentiment_test_pred, target_names=sentiments_list)\n",
    "print(\"Predicted Sentiment Classification Report (Test Set):\\n\")\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>predicted_category</th>\n",
       "      <th>polarity</th>\n",
       "      <th>predicted_polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Well, my first apple computer and I am impressed.</td>\n",
       "      <td>LAPTOP#GENERAL</td>\n",
       "      <td>LAPTOP#GENERAL</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Works well, fast and no reboots.</td>\n",
       "      <td>LAPTOP#OPERATION_PERFORMANCE</td>\n",
       "      <td>LAPTOP#OPERATION_PERFORMANCE</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Glad I did so far.</td>\n",
       "      <td>COMPANY#GENERAL</td>\n",
       "      <td>LAPTOP#GENERAL</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Glad I did so far.</td>\n",
       "      <td>LAPTOP#GENERAL</td>\n",
       "      <td>LAPTOP#GENERAL</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s.... L .... o..... w....  rea......llllyy  slow.</td>\n",
       "      <td>LAPTOP#OPERATION_PERFORMANCE</td>\n",
       "      <td>LAPTOP#OPERATION_PERFORMANCE</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Well, my first apple computer and I am impressed.   \n",
       "1                   Works well, fast and no reboots.   \n",
       "2                                 Glad I did so far.   \n",
       "3                                 Glad I did so far.   \n",
       "4  s.... L .... o..... w....  rea......llllyy  slow.   \n",
       "\n",
       "                       category            predicted_category  polarity  \\\n",
       "0                LAPTOP#GENERAL                LAPTOP#GENERAL  positive   \n",
       "1  LAPTOP#OPERATION_PERFORMANCE  LAPTOP#OPERATION_PERFORMANCE  positive   \n",
       "2               COMPANY#GENERAL                LAPTOP#GENERAL  positive   \n",
       "3                LAPTOP#GENERAL                LAPTOP#GENERAL  positive   \n",
       "4  LAPTOP#OPERATION_PERFORMANCE  LAPTOP#OPERATION_PERFORMANCE  negative   \n",
       "\n",
       "  predicted_polarity  \n",
       "0           positive  \n",
       "1           positive  \n",
       "2           positive  \n",
       "3           positive  \n",
       "4           negative  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert sentiment predictions to words and add to test test reviews data frame\n",
    "test_processed_df['predicted_polarity'] = convert_numerical_predictions(Y_sentiment_test_pred, polarity_label_dict)\n",
    "test_reviews_df['predicted_polarity'] = convert_numerical_predictions(Y_sentiment_test_pred, polarity_label_dict)\n",
    "\n",
    "test_reviews_df[['text','category','predicted_category','polarity','predicted_polarity']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Part 1 test data:\n",
      "Overall accuracy for correct category and sentiment predictions: 32%\n"
     ]
    }
   ],
   "source": [
    "# View the % of predictions where both the category AND polarity were predicted correct\n",
    "combined_accuracy = overall_accuracy_absa(test_reviews_df)\n",
    "print(\"For Part 1 test data:\")\n",
    "print(combined_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Evaluation (Part 1)__\n",
    "__Results:__\n",
    "- Category predictions test set accuracy score of $46$% is $37$% lower than the E#A category predictions on the training data ($83$%) but much better than random predictions that would yield an expected accuracy score of $1.5$%.\n",
    "    - The category prediction uses two separate Logistic Regression classifiers, one for entity and another for attribute predictions. The predictions are then combined. As a consequence of this, category prediction suffers from compounding errors.\n",
    "- The sentiment Logistic Regression classifier achieves an overall test accuracy of $65$%, compared to the training accuracy of $84$%.\n",
    "    - Positive review predictions perform well on the test set with precision, recall and f1-score all above $70$% for positive-sentiment examples.\n",
    "    - Negative review predictions perform better than random guess ($33$%) but are less accurate than the positive review predictions\n",
    "    - The performance for identifying neutral sentence reviews is particularly low, this is most likely due to the small number of neutral training set examples (188 out of 2909) compared to the number of positive and negative examples. Insufficient neutral training examples to learn predictive neutral review features using current method.\n",
    "\n",
    "__Time Efficiency:__\n",
    "\n",
    "_N.B. time efficiency results produced with macbook air M1 (2020), 8GB RAM._\n",
    "- Time taken to process, predict and produce classification reports for test data: $13.1s$\n",
    "- The most time expensive part of the process of predicting the aspect based sentiment predictions is the _filter_sentiment_input()_ function.\n",
    "    - This function uses the _spacy cosine similarity_ measure to compute the similarity between two documents. \n",
    "    - Upon investigation, it is specifically this calculation that is contributing to more than 50% of the time taken to process and predict the test data.\n",
    "- Therefore, a simple future improvement that could help significantly improve the time efficiency of the algorithm is to find a suitable working replacement for the _spacy similarity_ function used within the _filter_sentiment_input()_ function.\n",
    "\n",
    "__Future Improvements:__\n",
    "- The classification for both categories and sentiments could possibly be improved by identifying more information about the sentence structure via part of speech tagging. This may provide a method to produce more predictive input features for category classification. \n",
    "    - Additionally, relevant parts of sentence for category-based sentiment classification could be more efficiently extracted by considering wider sentence structure.\n",
    "- Further improving the quality of input features (e.g., by using word embeddings) may enable a more 'complex' model such as a Recurrent Neural Network (RNN) to generalise better to unseen data and produce better test set results than those that have been achieved with Logistic Regression.\n",
    "- Finally, a larger amount of labelled training data (especidally neutral sentiment examples) would likely lead to training more accurate models that perform better on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2\n",
    "_Perform aspect based sentiment analysis at the review level; expand multiclass sentiment classification to identify conflicting reviews; classify overall sentiment for LAPTOP#GENERAL category if not already identified._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) __Parse xml training data:__\n",
    "- Parse into pandas data frame to be able to work with it at the sentence level\n",
    "- Text column contains entire review text for each E#A pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse xml file into pandas data frame to work with at the review level\n",
    "def part2_xml_to_df(filename):\n",
    "    tree = ET.parse(filename)\n",
    "    root = tree.getroot()\n",
    "    reviews = root.findall('Review')\n",
    "    df_columns = ['rid','text','category','predicted_category','polarity','predicted_polarity']\n",
    "    reviews_df = pd.DataFrame(columns=df_columns)\n",
    "\n",
    "    for review in reviews:\n",
    "        rid = review.get('rid')\n",
    "        sentences = review.findall('sentences/sentence')\n",
    "        text = ''\n",
    "        for sentence in sentences:\n",
    "            text += sentence.find('text').text + ' '\n",
    "        opinions = review.findall('Opinions/Opinion')\n",
    "        for opinion in opinions:\n",
    "            category = opinion.get('category')\n",
    "            polarity = opinion.get('polarity')\n",
    "            predicted_category = ''\n",
    "            predicted_polarity = ''\n",
    "            reviews_df = pd.concat([reviews_df, \n",
    "                        pd.DataFrame([[rid, text, category, predicted_category, polarity, predicted_polarity]], \n",
    "                        columns=df_columns)], ignore_index=True)\n",
    "    \n",
    "    return reviews_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rid</th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>predicted_category</th>\n",
       "      <th>polarity</th>\n",
       "      <th>predicted_polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>348</td>\n",
       "      <td>Most everything is fine with this machine: spe...</td>\n",
       "      <td>LAPTOP#GENERAL</td>\n",
       "      <td></td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>348</td>\n",
       "      <td>Most everything is fine with this machine: spe...</td>\n",
       "      <td>LAPTOP#OPERATION_PERFORMANCE</td>\n",
       "      <td></td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>348</td>\n",
       "      <td>Most everything is fine with this machine: spe...</td>\n",
       "      <td>HARD_DISC#DESIGN_FEATURES</td>\n",
       "      <td></td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>348</td>\n",
       "      <td>Most everything is fine with this machine: spe...</td>\n",
       "      <td>LAPTOP#QUALITY</td>\n",
       "      <td></td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>348</td>\n",
       "      <td>Most everything is fine with this machine: spe...</td>\n",
       "      <td>DISPLAY#QUALITY</td>\n",
       "      <td></td>\n",
       "      <td>negative</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rid                                               text  \\\n",
       "0  348  Most everything is fine with this machine: spe...   \n",
       "1  348  Most everything is fine with this machine: spe...   \n",
       "2  348  Most everything is fine with this machine: spe...   \n",
       "3  348  Most everything is fine with this machine: spe...   \n",
       "4  348  Most everything is fine with this machine: spe...   \n",
       "\n",
       "                       category predicted_category  polarity  \\\n",
       "0                LAPTOP#GENERAL                     positive   \n",
       "1  LAPTOP#OPERATION_PERFORMANCE                     positive   \n",
       "2     HARD_DISC#DESIGN_FEATURES                     positive   \n",
       "3                LAPTOP#QUALITY                     positive   \n",
       "4               DISPLAY#QUALITY                     negative   \n",
       "\n",
       "  predicted_polarity  \n",
       "0                     \n",
       "1                     \n",
       "2                     \n",
       "3                     \n",
       "4                     "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_reviews_df_p2 = part2_xml_to_df(filename='Laptops_Train_p2.xml')\n",
    "train_reviews_df_p2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) __Processing__\n",
    "- Create copy of original data frame, to work with to determine classifications\n",
    "- Preprocess review text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rid</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>category</th>\n",
       "      <th>predicted_category</th>\n",
       "      <th>polarity</th>\n",
       "      <th>predicted_polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>348</td>\n",
       "      <td>everyth fine machin speed capac build thing un...</td>\n",
       "      <td>LAPTOP#GENERAL</td>\n",
       "      <td></td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>348</td>\n",
       "      <td>everyth fine machin speed capac build thing un...</td>\n",
       "      <td>LAPTOP#OPERATION_PERFORMANCE</td>\n",
       "      <td></td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>348</td>\n",
       "      <td>everyth fine machin speed capac build thing un...</td>\n",
       "      <td>HARD_DISC#DESIGN_FEATURES</td>\n",
       "      <td></td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>348</td>\n",
       "      <td>everyth fine machin speed capac build thing un...</td>\n",
       "      <td>LAPTOP#QUALITY</td>\n",
       "      <td></td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>348</td>\n",
       "      <td>everyth fine machin speed capac build thing un...</td>\n",
       "      <td>DISPLAY#QUALITY</td>\n",
       "      <td></td>\n",
       "      <td>negative</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rid                                     processed_text  \\\n",
       "0  348  everyth fine machin speed capac build thing un...   \n",
       "1  348  everyth fine machin speed capac build thing un...   \n",
       "2  348  everyth fine machin speed capac build thing un...   \n",
       "3  348  everyth fine machin speed capac build thing un...   \n",
       "4  348  everyth fine machin speed capac build thing un...   \n",
       "\n",
       "                       category predicted_category  polarity  \\\n",
       "0                LAPTOP#GENERAL                     positive   \n",
       "1  LAPTOP#OPERATION_PERFORMANCE                     positive   \n",
       "2     HARD_DISC#DESIGN_FEATURES                     positive   \n",
       "3                LAPTOP#QUALITY                     positive   \n",
       "4               DISPLAY#QUALITY                     negative   \n",
       "\n",
       "  predicted_polarity  \n",
       "0                     \n",
       "1                     \n",
       "2                     \n",
       "3                     \n",
       "4                     "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df_p2 = train_reviews_df_p2.copy()\n",
    "processed_df_p2['text'] = preprocess(tokenise(train_reviews_df_p2['text']))\n",
    "processed_df_p2 = processed_df_p2.rename(columns={\"text\": \"processed_text\"})\n",
    "processed_df_p2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) __Identify entity-attribute (E#A) pairs__\n",
    "- Part 2 training and test sets contain the same sentences and reviews from Part 1, difference being that category and polarity are annotated at the review level.\n",
    "- Therefore, can use the identified E#A categories for each review in part 1 for part 2. With some added functionality:\n",
    "    - If LAPTOP#GENERAL not predicted for a given review, include LAPTOP#GENERAL as category\n",
    "    - If the same category is predicted more than once for the same review, remove the duplicates and predict the next most likely category using spacy cosine similarity measure.\n",
    "- Output predictions in new prediction column in dataframe\n",
    "- Determine training accuracy for category predictions\n",
    "- Classification report will be produced for test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Defining functions used to obtain category predictions in Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorted_predictions_p2(df):\n",
    "    # Updated for Part 2 to query unique review id isntead of sentence id\n",
    "    # Aligns predictions with matching labels for sentences that have multiple opinions.\n",
    "    # e.g., ground truth for sentence id=1: LAPTOP#GENERAL, LAPTOP#BATTERY_PERFORMANCE\n",
    "    # predictions for sentence id=1 pre-alignment: LAPTOP#BATTERY_PERFORMANCE, LAPTOP#GENERAL\n",
    "    # predictions post-alignment: LAPTOP#GENERAL, LAPTOP#BATTERY_PERFORMANCE\n",
    "\n",
    "    N = len(df['category'])\n",
    "    labels_dict = {}\n",
    "    predictions_dict = {}\n",
    "    sorted_predictions = []\n",
    "    i = 0\n",
    "    tmp = 0\n",
    "\n",
    "    for rid in df['rid'].unique():\n",
    "        labels_dict[rid] = list(df.query(f\"rid == '{rid}'\")['category'])\n",
    "        predictions_dict[rid] = list(df.query(f\"rid == '{rid}'\")['predicted_category'])\n",
    "\n",
    "    for key in labels_dict.keys():\n",
    "        for value in labels_dict[key]:\n",
    "            if value in predictions_dict[key]:\n",
    "\n",
    "                idx = labels_dict[key].index(value) # obtain label index for matching label & prediction for given sentence id\n",
    "                idx2 = predictions_dict[key].index(value) # obtain prediction index for matching label & prediction for given sentence id\n",
    "\n",
    "                tmp = predictions_dict[key][idx]\n",
    "\n",
    "                predictions_dict[key][idx] = value # re-order predictions so that they align with ground truth for given id\n",
    "                predictions_dict[key][idx2] = tmp # swap changed values in predictions list for sentence id\n",
    "    \n",
    "    for values in predictions_dict.values():\n",
    "        for value in values:\n",
    "            sorted_predictions.append(value)\n",
    "\n",
    "    return list(sorted_predictions)\n",
    "\n",
    "def identify_p2_categories(df_p1, df_p2):\n",
    "    # Identify p2 categories given category predictions for sentences with \n",
    "    # matching review id from part 1\n",
    "    # Additional functionality: if LAPTOP#GENERAL not predicted, remove least\n",
    "    # similar predicted category and include LAPTOP#GENERAL as predicted category\n",
    "    # If same category predicted more than once, remove duplicate and predict new\n",
    "\n",
    "    categories = []\n",
    "    pred_cat = 'predicted_category'\n",
    "    for rid in df_p2['rid'].unique():\n",
    "        len_pred_cats_p1 = len(df_p1.query(f'rid == \"{rid}\"')[pred_cat])\n",
    "        len_pred_cats_p2 = len(df_p2.query(f'rid == \"{rid}\"')[pred_cat])\n",
    "        if 'LAPTOP#GENERAL' not in set(df_p1.query(f'rid == \"{rid}\"')[pred_cat]):\n",
    "            if len_pred_cats_p2 < len_pred_cats_p1:\n",
    "                categories += ['LAPTOP#GENERAL']\n",
    "                categories += list(df_p1.query(f'rid == \"{rid}\"')[pred_cat])[:len_pred_cats_p2-1]\n",
    "            elif len_pred_cats_p1 == len_pred_cats_p2:\n",
    "                categories += ['LAPTOP#GENERAL']\n",
    "                categories += list(df_p1.query(f'rid == \"{rid}\"')[pred_cat])[:len_pred_cats_p2-1]\n",
    "            else:  \n",
    "                delta = len_pred_cats_p2 - len_pred_cats_p1\n",
    "                categories += ['LAPTOP#GENERAL']\n",
    "                categories += list(df_p1.query(f'rid == \"{rid}\"')[pred_cat])\n",
    "                for i in range(delta-1):\n",
    "                    categories += ['LAPTOP#GENERAL'] # duplicate predictions will be handled later\n",
    "\n",
    "        else:\n",
    "            if len_pred_cats_p2 < len_pred_cats_p1:\n",
    "                if 'LAPTOP#GENERAL' in list(df_p1.query(f'rid == \"{rid}\"')[pred_cat])[:len_pred_cats_p2]:\n",
    "                    categories += list(df_p1.query(f'rid == \"{rid}\"')[pred_cat])[:len_pred_cats_p2]\n",
    "                else:\n",
    "                    categories += ['LAPTOP#GENERAL']\n",
    "                    categories += list(df_p1.query(f'rid == \"{rid}\"')[pred_cat])[:len_pred_cats_p2-1]\n",
    "            elif len_pred_cats_p1 == len_pred_cats_p2:\n",
    "                categories += list(df_p1.query(f'rid == \"{rid}\"')[pred_cat])\n",
    "            else:\n",
    "                delta = len_pred_cats_p2 - len_pred_cats_p1\n",
    "                categories += list(df_p1.query(f'rid == \"{rid}\"')['predicted_category'])\n",
    "                for i in range(delta):\n",
    "                    categories += ['LAPTOP#GENERAL'] # duplicate predictions will be handled later\n",
    "\n",
    "    return categories\n",
    "\n",
    "def repredict_duplicate_cats(process_df, clean_df, attrib_list=attributes_list, ent_list=entities_list):\n",
    "    # Identify duplicate predicted categories for each given review\n",
    "    # Use spacy cosine similarity measure to re-predict new categories\n",
    "    categories_new = []\n",
    "    for rid in process_df['rid'].unique():\n",
    "        if len(set(process_df.query(f'rid == \"{rid}\"')['predicted_category'])) < len(list(process_df.query(f'rid == \"{rid}\"')['predicted_category'])):\n",
    "            categories_new += set(process_df.query(f'rid == \"{rid}\"')['predicted_category'])\n",
    "\n",
    "            delta = len(list(process_df.query(f'rid == \"{rid}\"')['predicted_category'])) - len(set(process_df.query(f'rid == \"{rid}\"')['predicted_category']))\n",
    "            unique_cats = list(set(process_df.query(f'rid == \"{rid}\"')['predicted_category']))\n",
    "            duplicates = list(process_df.query(f'rid == \"{rid}\"')['predicted_category'])\n",
    "            [duplicates.remove(item) for item in unique_cats if item in duplicates]\n",
    "\n",
    "            # predict new category from ranked list of 20 most similar categories\n",
    "            review_text = clean_df.query(f'rid == \"{rid}\"')['text'].unique()[0]\n",
    "\n",
    "            entity_sim_dict = {}\n",
    "            for entity in ent_list[:5]:\n",
    "                entity_sim_dict[entity] = nlp(entity).similarity(nlp(review_text))\n",
    "            sorted_entities = sorted(((value,key) for key,value in entity_sim_dict.items()), reverse=True)\n",
    "\n",
    "            attrib_sim_dict = {}\n",
    "            for attrib in attrib_list[:4]:\n",
    "                attrib_sim_dict[attrib] = nlp(attrib).similarity(nlp(review_text))\n",
    "            sorted_attribs = sorted(((value,key) for key,value in attrib_sim_dict.items()), reverse=True)\n",
    "\n",
    "            unsorted_categories = {}\n",
    "            for i in sorted_entities:\n",
    "                for j in sorted_attribs:\n",
    "                    unsorted_categories[i[1]+'#'+j[1]] = i[0]*j[0]\n",
    "\n",
    "            sorted_categories = sorted(((value,key) for key,value in unsorted_categories.items()), reverse=True)\n",
    "            ranked_categories = [i[1] for i in sorted_categories]\n",
    "\n",
    "            # Only keep ranked_categories that are not already in unique_cats\n",
    "            [ranked_categories.remove(item) for item in ranked_categories if item in unique_cats]\n",
    "\n",
    "            for i in range(delta):\n",
    "                categories_new += [ranked_categories[i]]\n",
    "    \n",
    "        else:\n",
    "            categories_new += set(process_df.query(f'rid == \"{rid}\"')['predicted_category'])\n",
    "        \n",
    "    return categories_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Identifying predicted categories for each review in Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# populating E#A category predictions given that the part 2 data contains the same sentences as part 1\n",
    "processed_df_p2['predicted_category'] = identify_p2_categories(train_reviews_df, train_reviews_df_p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-predict duplicate predicted categories for given review\n",
    "# Note: cell takes ~45secs to run\n",
    "processed_df_p2['predicted_category'] = repredict_duplicate_cats(processed_df_p2, train_reviews_df_p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort category predictions for more representative accuracy score (see example in function comments)\n",
    "processed_df_p2['predicted_category'] = sorted_predictions_p2(processed_df_p2)\n",
    "train_reviews_df_p2['predicted_category'] = sorted_predictions_p2(processed_df_p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set category predictions accuracy score: 71%\n"
     ]
    }
   ],
   "source": [
    "e_a_labels_p2, e_a_predictions_p2, e_a_list_p2, e_a_label_dict_p2  = numerical_entity_attributes(processed_df_p2)\n",
    "category_train_accuracy_p2 = accuracy_score(e_a_labels_p2, e_a_predictions_p2)\n",
    "\n",
    "print(f\"Training set category predictions accuracy score: {category_train_accuracy_p2*100:.0f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Worse category predictions than Part 1 training set predictions ($71$% vs $83$%)\n",
    "    - This might be due to removing repeat predictions. For example, the classifiers are more likely to predict LAPTOP#GENERAL for a given example as this is the most common category in the training data.\n",
    "    - For Part 1, this works well. For example, 2 sentences in the same review may belong to LAPTOP#GENERAL. The classifiers in Part 1 can identify this with high accuracy.\n",
    "    - However now for Part 2, each review only has at most one category of each kind. Therefore the accuracy now depends more on how well the classifiers can identify categories that occur less frequently in the training data.\n",
    "    - As seen in the Part 1 test set classification report, the classifiers perform worse when trying to identify categories that occur less frequently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rid</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>category</th>\n",
       "      <th>predicted_category</th>\n",
       "      <th>polarity</th>\n",
       "      <th>predicted_polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>348</td>\n",
       "      <td>everyth fine machin speed capac build thing un...</td>\n",
       "      <td>LAPTOP#GENERAL</td>\n",
       "      <td>LAPTOP#GENERAL</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>348</td>\n",
       "      <td>everyth fine machin speed capac build thing un...</td>\n",
       "      <td>LAPTOP#OPERATION_PERFORMANCE</td>\n",
       "      <td>LAPTOP#OPERATION_PERFORMANCE</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>348</td>\n",
       "      <td>everyth fine machin speed capac build thing un...</td>\n",
       "      <td>HARD_DISC#DESIGN_FEATURES</td>\n",
       "      <td>LAPTOP#DESIGN_FEATURES</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>348</td>\n",
       "      <td>everyth fine machin speed capac build thing un...</td>\n",
       "      <td>LAPTOP#QUALITY</td>\n",
       "      <td>LAPTOP#QUALITY</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>348</td>\n",
       "      <td>everyth fine machin speed capac build thing un...</td>\n",
       "      <td>DISPLAY#QUALITY</td>\n",
       "      <td>DISPLAY#QUALITY</td>\n",
       "      <td>negative</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rid                                     processed_text  \\\n",
       "0  348  everyth fine machin speed capac build thing un...   \n",
       "1  348  everyth fine machin speed capac build thing un...   \n",
       "2  348  everyth fine machin speed capac build thing un...   \n",
       "3  348  everyth fine machin speed capac build thing un...   \n",
       "4  348  everyth fine machin speed capac build thing un...   \n",
       "\n",
       "                       category            predicted_category  polarity  \\\n",
       "0                LAPTOP#GENERAL                LAPTOP#GENERAL  positive   \n",
       "1  LAPTOP#OPERATION_PERFORMANCE  LAPTOP#OPERATION_PERFORMANCE  positive   \n",
       "2     HARD_DISC#DESIGN_FEATURES        LAPTOP#DESIGN_FEATURES  positive   \n",
       "3                LAPTOP#QUALITY                LAPTOP#QUALITY  positive   \n",
       "4               DISPLAY#QUALITY               DISPLAY#QUALITY  negative   \n",
       "\n",
       "  predicted_polarity  \n",
       "0                     \n",
       "1                     \n",
       "2                     \n",
       "3                     \n",
       "4                     "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reorder columns\n",
    "reorder_columns = ['rid','processed_text','entity','entity_label',\n",
    "                  'attribute','attribute_label','category','predicted_category',\n",
    "                  'polarity','predicted_polarity']\n",
    "\n",
    "processed_df_p2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) __Perform sentiment analysis at the review level for each identified E#A pair__\n",
    "- Using trained Sentiment classifier from Part 1\n",
    "- Some differences in sentiment classification approach:\n",
    "    - For each predicted category, assign the 2 most similar sentences as determined by cosine similarity as input features\n",
    "    - Predict polarity of each assigned sentence to category\n",
    "    - If sentiment prediction for the two assigned sentences is positive and negative, then predict conflict\n",
    "    - If sentiment prediction is positive and neutral, predict positive; similarly for negative and neutral predictions\n",
    "    - If both sentences are neutral, predict neutral\n",
    "    - If predicted category is LAPTOP#GENERAL, then use entire review to make sentiment prediction\n",
    "- Output predictions in prediction column in dataframe\n",
    "- Measure predictions on training data with overall accuracy score\n",
    "    - Classification report will be produced for test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Defining functions used to obtain sentiment predictions in part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_text_p2(text):\n",
    "    # Split input review into list of sentences.\n",
    "    split_input = []\n",
    "    for review in text:\n",
    "        split_input.append(sent_tokenize(review))\n",
    "        \n",
    "    return split_input\n",
    "\n",
    "def filter_sentiment_input_p2(text, cat, threshold=1):\n",
    "    # If predicted LAPTOP#GENERAL, keep entire review text.\n",
    "    # If one sentence in review is much more similar to predicted category\n",
    "    # than the next most similar sentence, keep only that sentence for sentiment prediction.\n",
    "    # Else keep the two most similar sentences for given category from review.\n",
    "\n",
    "    filtered_input_1 = []\n",
    "    filtered_input_2 = []\n",
    "    for idx, review in enumerate(text):\n",
    "        if cat[idx] == 'LAPTOP#GENERAL':\n",
    "            filtered_input_1.append(' '.join(review))\n",
    "            filtered_input_2.append(' '.join(review))\n",
    "        else:\n",
    "            cat_list = re.split('_|#', cat[idx])\n",
    "            cat_list = [item.title() if item != 'OS' else item for item in cat_list]\n",
    "            category = nlp(' '.join(cat_list))\n",
    "\n",
    "            sent_sim_dict = {}\n",
    "            for sentence in review:\n",
    "                sent_sim_dict[sentence] = category.similarity(nlp(sentence))\n",
    "            \n",
    "            sorted_sents = sorted(((value,key) for key,value in sent_sim_dict.items()), reverse=True)\n",
    "            \n",
    "            if len(sorted_sents) > 1:\n",
    "                # threshold hyperparameter determined on training set\n",
    "                if (sorted_sents[0][0] - sorted_sents[1][0]) < threshold:\n",
    "                    filtered_input_1.append(sorted_sents[0][1])\n",
    "                    filtered_input_2.append(sorted_sents[1][1])\n",
    "                else:\n",
    "                    filtered_input_1.append(sorted_sents[0][1])\n",
    "                    filtered_input_2.append(sorted_sents[0][1])\n",
    "            else:\n",
    "                filtered_input_1.append(sorted_sents[0][1])\n",
    "                filtered_input_2.append(sorted_sents[0][1])\n",
    "                \n",
    "    return filtered_input_1, filtered_input_2\n",
    "\n",
    "def p2_sentiment_predictions(input_1, input_2):\n",
    "    # make sentiment predictions\n",
    "    # polarity_labels_dict = {0: 'positive', 1: 'negative', 2: 'neutral', 3: 'conflict'} \n",
    "    N,D  = input_1.shape\n",
    "    Y_sentiment_pred = np.zeros(N)\n",
    "\n",
    "    for i in range(N):\n",
    "        prediction_1 = sentiment_count_lr.predict(input_1[i,:])\n",
    "        prediction_2 = sentiment_count_lr.predict(input_2[i,:])\n",
    "        \n",
    "        if prediction_1 == prediction_2:\n",
    "            Y_sentiment_pred[i] = prediction_1\n",
    "\n",
    "        # if prediction is positive and negative\n",
    "        elif prediction_1 == 0 and prediction_2 == 1:\n",
    "            Y_sentiment_pred[i] = 3 # numerical value for conflict\n",
    "\n",
    "        # if prediction is positive and neutral\n",
    "        elif prediction_1 == 0 or prediction_2 == 0: \n",
    "            Y_sentiment_pred[i] = 0 # numerical value for positive\n",
    "\n",
    "        # if prediction is negative and neutral\n",
    "        elif prediction_1 == 1 or prediction_2 == 1: \n",
    "            Y_sentiment_pred[i] = 1 # numerical prediction for negative\n",
    "\n",
    "        # If prediction is neutral for both sentences\n",
    "        else:\n",
    "            Y_sentiment_pred[i] = 2 # numerical prediction for neutral\n",
    "        \n",
    "    return Y_sentiment_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Making sentiment predictions for Part 2 training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label part 2 training sentiments\n",
    "sentiments_list_p2, polarity_label_dict_p2 = numerical_labels(processed_df_p2, 'polarity', 'polarity_label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training labels for part 2 sentiment classification\n",
    "Y_sentiment_train_p2 = processed_df_p2['polarity_label']\n",
    "Y_sentiment_train_p2 = np.array(Y_sentiment_train_p2, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating copy of data frame to populate with processed input text\n",
    "# specifically processed for sentiment prediction\n",
    "sentiment_processed_df_p2 = train_reviews_df_p2.copy()\n",
    "sentiment_processed_df_p2['text'] = split_input_text_p2(train_reviews_df_p2['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N.B. cell takes ~60secs to run\n",
    "sentiment_processed_df_p2['text_1'],sentiment_processed_df_p2['text_2'] = filter_sentiment_input_p2(sentiment_processed_df_p2['text'],\n",
    "                                        sentiment_processed_df_p2['predicted_category'],\n",
    "                                        threshold=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre process input features for sentiment classification\n",
    "# two sets of input features\n",
    "# If predicted sentiments for each set is different, predict conflict\n",
    "sentiment_processed_df_p2['processed_text_1'] = preprocess(tokenise(sentiment_processed_df_p2['text_1']))\n",
    "X_train_sentiment_p2_1 = count_vectorizer.transform(sentiment_processed_df_p2['processed_text_1'])\n",
    "\n",
    "sentiment_processed_df_p2['processed_text_2'] = preprocess(tokenise(sentiment_processed_df_p2['text_2']))\n",
    "X_train_sentiment_p2_2 = count_vectorizer.transform(sentiment_processed_df_p2['processed_text_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set sentiment prediction accuracy score: 76%\n"
     ]
    }
   ],
   "source": [
    "# Make sentiment predictions on part 2 Training data\n",
    "Y_sentiment_train_pred_p2 = p2_sentiment_predictions(X_train_sentiment_p2_1, X_train_sentiment_p2_2)\n",
    "\n",
    "sentiment_train_accuracy_p2 = accuracy_score(Y_sentiment_train_p2, Y_sentiment_train_pred_p2)\n",
    "print(f\"Training set sentiment prediction accuracy score: {sentiment_train_accuracy_p2*100:.0f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.80      0.86      0.83      1210\n",
      "    negative       0.81      0.74      0.77       708\n",
      "     neutral       0.15      0.09      0.11       123\n",
      "    conflict       0.04      0.05      0.04        41\n",
      "\n",
      "    accuracy                           0.76      2082\n",
      "   macro avg       0.45      0.43      0.44      2082\n",
      "weighted avg       0.75      0.76      0.75      2082\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cr = classification_report(Y_sentiment_train_p2, Y_sentiment_train_pred_p2, target_names=sentiments_list_p2)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The overall sentiment accuracy on the training data is good at $76$%, slightly worse than $84$% accuracy for Part 1\n",
    "    - The neutral and conflict predictions are very imprecise ($15$% and $4$% respectively), this brings down the overall accuracy.  \n",
    "    - Part of the difficulty is due to relatively very few examples being labeled as neurtral or conflict, making them very hard to find and predict using the current approach.\n",
    "    - Only 41 conflict and 123 neutral labelled training examples out of 2082"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) __Evaluate accuracy__\n",
    "    - Measure E#A pair prediction and sentiment prediction test set accuracy\n",
    "    - Using classification report for category and sentiment predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rid</th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>predicted_category</th>\n",
       "      <th>polarity</th>\n",
       "      <th>predicted_polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>348</td>\n",
       "      <td>Most everything is fine with this machine: spe...</td>\n",
       "      <td>LAPTOP#GENERAL</td>\n",
       "      <td>LAPTOP#GENERAL</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>348</td>\n",
       "      <td>Most everything is fine with this machine: spe...</td>\n",
       "      <td>LAPTOP#OPERATION_PERFORMANCE</td>\n",
       "      <td>LAPTOP#OPERATION_PERFORMANCE</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>348</td>\n",
       "      <td>Most everything is fine with this machine: spe...</td>\n",
       "      <td>HARD_DISC#DESIGN_FEATURES</td>\n",
       "      <td>LAPTOP#DESIGN_FEATURES</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rid                                               text  \\\n",
       "0  348  Most everything is fine with this machine: spe...   \n",
       "1  348  Most everything is fine with this machine: spe...   \n",
       "2  348  Most everything is fine with this machine: spe...   \n",
       "\n",
       "                       category            predicted_category  polarity  \\\n",
       "0                LAPTOP#GENERAL                LAPTOP#GENERAL  positive   \n",
       "1  LAPTOP#OPERATION_PERFORMANCE  LAPTOP#OPERATION_PERFORMANCE  positive   \n",
       "2     HARD_DISC#DESIGN_FEATURES        LAPTOP#DESIGN_FEATURES  positive   \n",
       "\n",
       "  predicted_polarity  \n",
       "0                     \n",
       "1                     \n",
       "2                     "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_reviews_df_p2 = part2_xml_to_df(filename='Laptops_Test_p2_gold.xml')\n",
    "train_reviews_df_p2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rid</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>category</th>\n",
       "      <th>predicted_category</th>\n",
       "      <th>polarity</th>\n",
       "      <th>predicted_polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B0074703CM_108_ANONYMOUS</td>\n",
       "      <td>well first appl comput impress work well fast ...</td>\n",
       "      <td>LAPTOP#OPERATION_PERFORMANCE</td>\n",
       "      <td></td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B0074703CM_108_ANONYMOUS</td>\n",
       "      <td>well first appl comput impress work well fast ...</td>\n",
       "      <td>COMPANY#GENERAL</td>\n",
       "      <td></td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B0074703CM_108_ANONYMOUS</td>\n",
       "      <td>well first appl comput impress work well fast ...</td>\n",
       "      <td>LAPTOP#GENERAL</td>\n",
       "      <td></td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        rid  \\\n",
       "0  B0074703CM_108_ANONYMOUS   \n",
       "1  B0074703CM_108_ANONYMOUS   \n",
       "2  B0074703CM_108_ANONYMOUS   \n",
       "\n",
       "                                      processed_text  \\\n",
       "0  well first appl comput impress work well fast ...   \n",
       "1  well first appl comput impress work well fast ...   \n",
       "2  well first appl comput impress work well fast ...   \n",
       "\n",
       "                       category predicted_category  polarity  \\\n",
       "0  LAPTOP#OPERATION_PERFORMANCE                     positive   \n",
       "1               COMPANY#GENERAL                     positive   \n",
       "2                LAPTOP#GENERAL                     positive   \n",
       "\n",
       "  predicted_polarity  \n",
       "0                     \n",
       "1                     \n",
       "2                     "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_processed_df_p2 = test_reviews_df_p2.copy()\n",
    "test_processed_df_p2['text'] = preprocess(tokenise(test_reviews_df_p2['text']))\n",
    "test_processed_df_p2 = test_processed_df_p2.rename(columns={\"text\": \"processed_text\"})\n",
    "test_processed_df_p2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# populating E#A category predictions given that the part 2 data contains the same sentences as part 1\n",
    "test_processed_df_p2['predicted_category'] = identify_p2_categories(test_reviews_df, test_reviews_df_p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-predict duplicate predicted categories for given review\n",
    "# Note: cell takes ~20secs to run\n",
    "test_processed_df_p2['predicted_category'] = repredict_duplicate_cats(test_processed_df_p2, test_reviews_df_p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort category predictions for more representative accuracy score (see example in function comments)\n",
    "test_processed_df_p2['predicted_category'] = sorted_predictions_p2(test_processed_df_p2)\n",
    "test_reviews_df_p2['predicted_category'] = sorted_predictions_p2(test_processed_df_p2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Produce Classification report for E#A pair predictions on Part 2 test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Part 2) Predicted E#A Category Classification Report (Test Set):\n",
      "\n",
      "                                    precision    recall  f1-score   support\n",
      "\n",
      "      LAPTOP#OPERATION_PERFORMANCE       0.76      0.79      0.77        47\n",
      "                   COMPANY#GENERAL       1.00      0.08      0.15        24\n",
      "                    LAPTOP#GENERAL       1.00      1.00      1.00        80\n",
      "                  LAPTOP#USABILITY       0.58      0.70      0.64        30\n",
      "              LAPTOP#MISCELLANEOUS       0.59      0.42      0.49        24\n",
      "            LAPTOP#DESIGN_FEATURES       0.78      0.79      0.78        39\n",
      "                LAPTOP#PORTABILITY       0.00      0.00      0.00         5\n",
      "     BATTERY#OPERATION_PERFORMANCE       0.90      0.64      0.75        14\n",
      "                      LAPTOP#PRICE       0.91      0.37      0.53        27\n",
      "         HARD_DISC#DESIGN_FEATURES       0.83      0.56      0.67         9\n",
      "                    LAPTOP#QUALITY       0.57      0.90      0.69        29\n",
      "                   DISPLAY#QUALITY       0.67      0.19      0.30        21\n",
      "              POWER_SUPPLY#GENERAL       0.00      0.00      0.00         1\n",
      "        MULTIMEDIA_DEVICES#QUALITY       0.67      0.50      0.57         4\n",
      "                  SHIPPING#QUALITY       0.00      0.00      0.00         1\n",
      "    OPTICAL_DRIVES#DESIGN_FEATURES       0.00      0.00      0.00         1\n",
      "        MULTIMEDIA_DEVICES#GENERAL       1.00      0.33      0.50         3\n",
      "                      OS#USABILITY       0.80      0.27      0.40        15\n",
      "                        OS#GENERAL       0.25      0.11      0.15         9\n",
      "             MOUSE#DESIGN_FEATURES       0.50      0.50      0.50         4\n",
      "          KEYBOARD#DESIGN_FEATURES       0.38      0.38      0.38         8\n",
      "           DISPLAY#DESIGN_FEATURES       0.50      0.17      0.25        12\n",
      "                   MOUSE#USABILITY       1.00      0.33      0.50         9\n",
      "      POWER_SUPPLY#DESIGN_FEATURES       0.00      0.00      0.00         2\n",
      "                 HARD_DISC#GENERAL       0.00      0.00      0.00         2\n",
      "                   DISPLAY#GENERAL       0.00      0.00      0.00         4\n",
      "    KEYBOARD#OPERATION_PERFORMANCE       0.00      0.00      0.00         4\n",
      "                   SUPPORT#QUALITY       0.67      0.36      0.47        11\n",
      "            MEMORY#DESIGN_FEATURES       1.00      0.29      0.44         7\n",
      "         CPU#OPERATION_PERFORMANCE       0.00      0.00      0.00         3\n",
      "               LAPTOP#CONNECTIVITY       0.00      0.00      0.00         7\n",
      "                KEYBOARD#USABILITY       1.00      0.50      0.67         6\n",
      "                SOFTWARE#USABILITY       0.67      0.33      0.44         6\n",
      "MULTIMEDIA_DEVICES#DESIGN_FEATURES       0.00      0.00      0.00         2\n",
      "                  KEYBOARD#QUALITY       0.50      0.20      0.29         5\n",
      "                 DISPLAY#USABILITY       1.00      0.20      0.33         5\n",
      "     DISPLAY#OPERATION_PERFORMANCE       0.25      0.17      0.20         6\n",
      "               CPU#DESIGN_FEATURES       0.00      0.00      0.00         3\n",
      "          GRAPHICS#DESIGN_FEATURES       1.00      0.50      0.67         2\n",
      "FANS_COOLING#OPERATION_PERFORMANCE       0.00      0.00      0.00         2\n",
      "                OS#DESIGN_FEATURES       0.00      0.00      0.00         5\n",
      "            OPTICAL_DRIVES#GENERAL       0.00      0.00      0.00         1\n",
      "          OS#OPERATION_PERFORMANCE       0.00      0.00      0.00         2\n",
      "                  OS#MISCELLANEOUS       0.00      0.00      0.00         2\n",
      "                   BATTERY#QUALITY       0.67      0.67      0.67         3\n",
      "                     SUPPORT#PRICE       0.00      0.00      0.00         2\n",
      "               MOTHERBOARD#QUALITY       0.00      0.00      0.00         2\n",
      "                  KEYBOARD#GENERAL       0.25      0.50      0.33         2\n",
      "                     MOUSE#GENERAL       0.33      0.33      0.33         3\n",
      "                  SOFTWARE#GENERAL       0.00      0.00      0.00         4\n",
      "       MOUSE#OPERATION_PERFORMANCE       0.33      0.50      0.40         2\n",
      "                  HARDWARE#QUALITY       0.00      0.00      0.00         3\n",
      "                 CPU#MISCELLANEOUS       0.00      0.00      0.00         1\n",
      "            GRAPHICS#MISCELLANEOUS       0.00      0.00      0.00         1\n",
      "      MULTIMEDIA_DEVICES#USABILITY       0.00      0.00      0.00         1\n",
      "   HARD_DISC#OPERATION_PERFORMANCE       0.12      0.33      0.18         3\n",
      "    SOFTWARE#OPERATION_PERFORMANCE       0.50      0.50      0.50         2\n",
      "                        OS#QUALITY       1.00      0.50      0.67         2\n",
      "       PORTS#OPERATION_PERFORMANCE       0.00      0.00      0.00         1\n",
      "          SOFTWARE#DESIGN_FEATURES       0.00      0.00      0.00         1\n",
      "                  SOFTWARE#QUALITY       0.00      0.00      0.00         2\n",
      "                  WARRANTY#GENERAL       0.00      0.00      0.00         1\n",
      "           BATTERY#DESIGN_FEATURES       0.00      0.00      0.00         1\n",
      "                       CPU#GENERAL       0.00      0.00      0.00         1\n",
      "                     MOUSE#QUALITY       0.50      0.50      0.50         2\n",
      "                 HARD_DISC#QUALITY       0.00      0.00      0.00         1\n",
      "                    SOFTWARE#PRICE       0.00      0.00      0.00         1\n",
      "                               N/A       0.00      0.00      0.00         0\n",
      "\n",
      "                          accuracy                           0.51       545\n",
      "                         macro avg       0.34      0.23      0.25       545\n",
      "                      weighted avg       0.66      0.51      0.53       545\n",
      "\n"
     ]
    }
   ],
   "source": [
    "e_a_labels_p2, e_a_predictions_p2, e_a_list_p2, e_a_label_dict_p2  = numerical_entity_attributes(test_processed_df_p2)\n",
    "\n",
    "cr = classification_report(e_a_labels_p2, e_a_predictions_p2, target_names=e_a_list_p2)\n",
    "print(\"(Part 2) Predicted E#A Category Classification Report (Test Set):\\n\")\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Classification report for sentiment predictions on Part 2 test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label part 2 test sentiments\n",
    "test_processed_df_p2['polarity_label'] = ''\n",
    "i = 0\n",
    "for label in sentiments_list_p2:\n",
    "    test_processed_df_p2.loc[test_processed_df_p2['polarity'] == label, 'polarity_label'] = i\n",
    "    polarity_label_dict_p2[i] = label\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test labels for part 2 sentiment classification\n",
    "Y_sentiment_test_p2 = test_processed_df_p2['polarity_label']\n",
    "Y_sentiment_test_p2 = np.array(Y_sentiment_test_p2, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating copy of data frame to populate with processed input text\n",
    "# specifically processed for sentiment prediction\n",
    "test_sentiment_prep_df_p2 = test_reviews_df_p2.copy()\n",
    "test_sentiment_prep_df_p2['text'] = split_input_text_p2(test_reviews_df_p2['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N.B. cell takes ~30secs to run\n",
    "test_sentiment_prep_df_p2['text_1'],test_sentiment_prep_df_p2['text_2'] = filter_sentiment_input_p2(test_sentiment_prep_df_p2['text'],\n",
    "                                        test_sentiment_prep_df_p2['predicted_category'],\n",
    "                                        threshold=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre process input features for sentiment classification\n",
    "# two sets of input features\n",
    "# If predicted sentiments for each set is positive & negative, predict conflict\n",
    "test_sentiment_prep_df_p2['processed_text_1'] = preprocess(tokenise(test_sentiment_prep_df_p2['text_1']))\n",
    "X_test_sentiment_p2_1 = count_vectorizer.transform(test_sentiment_prep_df_p2['processed_text_1'])\n",
    "\n",
    "test_sentiment_prep_df_p2['processed_text_2'] = preprocess(tokenise(test_sentiment_prep_df_p2['text_2']))\n",
    "X_test_sentiment_p2_2 = count_vectorizer.transform(test_sentiment_prep_df_p2['processed_text_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Part 2) Predicted Sentiment Classification Report (Test Set):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.70      0.81      0.75       338\n",
      "    negative       0.57      0.37      0.45       162\n",
      "     neutral       0.08      0.03      0.05        31\n",
      "    conflict       0.12      0.29      0.17        14\n",
      "\n",
      "    accuracy                           0.62       545\n",
      "   macro avg       0.37      0.37      0.35       545\n",
      "weighted avg       0.61      0.62      0.61       545\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make sentiment predictions on part 2 test data\n",
    "Y_sentiment_test_pred_p2 = p2_sentiment_predictions(X_test_sentiment_p2_1, X_test_sentiment_p2_2)\n",
    "\n",
    "# Produce classification report\n",
    "cr = classification_report(Y_sentiment_test_p2, Y_sentiment_test_pred_p2, target_names=sentiments_list_p2)\n",
    "print(\"(Part 2) Predicted Sentiment Classification Report (Test Set):\\n\")\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>predicted_category</th>\n",
       "      <th>polarity</th>\n",
       "      <th>predicted_polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Well, my first apple computer and I am impress...</td>\n",
       "      <td>LAPTOP#OPERATION_PERFORMANCE</td>\n",
       "      <td>LAPTOP#OPERATION_PERFORMANCE</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Well, my first apple computer and I am impress...</td>\n",
       "      <td>COMPANY#GENERAL</td>\n",
       "      <td>GRAPHICS#GENERAL</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Well, my first apple computer and I am impress...</td>\n",
       "      <td>LAPTOP#GENERAL</td>\n",
       "      <td>LAPTOP#GENERAL</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s.... L .... o..... w....  rea......llllyy  sl...</td>\n",
       "      <td>LAPTOP#OPERATION_PERFORMANCE</td>\n",
       "      <td>LAPTOP#OPERATION_PERFORMANCE</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s.... L .... o..... w....  rea......llllyy  sl...</td>\n",
       "      <td>LAPTOP#USABILITY</td>\n",
       "      <td>LAPTOP#USABILITY</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Well, my first apple computer and I am impress...   \n",
       "1  Well, my first apple computer and I am impress...   \n",
       "2  Well, my first apple computer and I am impress...   \n",
       "3  s.... L .... o..... w....  rea......llllyy  sl...   \n",
       "4  s.... L .... o..... w....  rea......llllyy  sl...   \n",
       "\n",
       "                       category            predicted_category  polarity  \\\n",
       "0  LAPTOP#OPERATION_PERFORMANCE  LAPTOP#OPERATION_PERFORMANCE  positive   \n",
       "1               COMPANY#GENERAL              GRAPHICS#GENERAL  positive   \n",
       "2                LAPTOP#GENERAL                LAPTOP#GENERAL  positive   \n",
       "3  LAPTOP#OPERATION_PERFORMANCE  LAPTOP#OPERATION_PERFORMANCE  negative   \n",
       "4              LAPTOP#USABILITY              LAPTOP#USABILITY  negative   \n",
       "\n",
       "  predicted_polarity  \n",
       "0           positive  \n",
       "1           positive  \n",
       "2           positive  \n",
       "3           positive  \n",
       "4           positive  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_processed_df_p2['predicted_polarity'] = convert_numerical_predictions(Y_sentiment_test_pred_p2, polarity_label_dict_p2)\n",
    "test_reviews_df_p2['predicted_polarity'] = convert_numerical_predictions(Y_sentiment_test_pred_p2, polarity_label_dict_p2)\n",
    "\n",
    "test_reviews_df_p2[['text','category','predicted_category','polarity','predicted_polarity']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Part 2 test data:\n",
      "Overall accuracy for correct category and sentiment predictions: 34%\n"
     ]
    }
   ],
   "source": [
    "# View the % of predictions where both the category AND polarity were predicted correct\n",
    "combined_accuracy_p2 = overall_accuracy_absa(test_reviews_df_p2)\n",
    "print(\"For Part 2 test data:\")\n",
    "print(combined_accuracy_p2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Evaluation (Part 2)__\n",
    "__Results:__\n",
    "- Category predictions test set accuracy score of $51$% is $20$% lower than the E#A category predictions on the training data ($71$%) but the accuracy is better than that of the test set category accuracy ($46$%) for Part 1.\n",
    "    - Interestingly, this may be due to the same reasons that make the category predictions accuracy worse on the Part 2 training data. Due to the information provided that each review must contain a LAPTOP#GENERAL category, a perfect score is achieved on predicting LAPTOP#GENERAL ($100$% for precision, recall and f-1 score). This will bring up overall accuracy\n",
    "    - A second reason for the improved test set accuracy may be the implementation of the function that removes and re-predicts duplicate predictions for each review. Part 1 has some functionality to avoid predicting duplicates but it there is still a small probability that it predicts duplicates for the same sentence.\n",
    "- Sentiment predictions test set accuracy score is $62$% and the approach can identify a small number of conflict labelled examples. Even though the test set accuracy is $3$% lower than that achieved on the Part 1 test set, this is still good considering that there are now 4 possible sentiment categories instead of 3.\n",
    "    - Again, positive review predictions perform well for the part 2 test set as seen in the classification report.\n",
    "    - Negative review predictions perform better than random guess ($25$%) but are less accurate than the positive review predictions.\n",
    "    - It is worth noting that the overall sentiment accuracy $62$% is equal to the naive approach of predicting _positive_ for all examples ($62$%). Part of the difficulty in achieving a higher overall accuracy is the poor prediction performance on neutral and conflict labelled examples.\n",
    "    - The predictions for neutral and conflict labelled examples are imprecise, dragging down the overall accuracy of the sentiment classifier. This suggests that overall sentiment accuracy can be significantly improved by using an approach that can better (and more precisely) identify both neutral and conflict labelled examples.\n",
    "\n",
    "__Time Efficiency:__\n",
    "\n",
    "_N.B. time efficiency results produced with macbook air M1 (2020), 8GB RAM._\n",
    "- Time taken to process, predict and produce classification reports for test data: $54.5s$\n",
    "- In addition to the time-costly _spacy cosine similarity_ function highlighted in the Evaluation section of Part 1, there are three other major contributors to the increase in time taken to process and make predictions for the test set in Part 2:\n",
    "    1) Firstly the system now pre-processes the entire review for each predicted category, rather than a single sentence like in Part 1. This results in the text pre-processing cells to take $6.9s$ for Part 2 vs $1s$ in Part 1.\n",
    "        - An obvious future improvement here would be to only pre-process the same review text for each review only once. The current system pre-processes the review text for each review as many times as the review has categories which is evidently inefficient.\n",
    "    2) The _repredict_duplicate_cats()_ function is very time costly ($17.3s$) because it again uses the costly _spacy similarity_ function and it also performs a series of sorting calculations and rankings to repredict duplicate categories. However, this function in particular is likely responsible for the improvement in the test set category classification accuracy compared to Part 1.\n",
    "    3) The other contibutor to the decrease in time efficiency for the algorithm in Part 2 is the _filter_sentiment_input_p2()_ function. This function again uses the costly _spacy similarity_ function to determine which sentences in the review to keep for the aspect based sentiment predictions.\n",
    "- Given the reasons stated for the main causes of increase in time of the algorithm, the most effective future improvement would be, as mentioned in Part 1 Evaluation section, to find a more efficient replacement for the _space similarity_ function that is used at several steps in the algorithm.\n",
    "    - One possible solution would be to re-use the classifiers to determine the similarity between the different parts of input text and the predicted categories.\n",
    "    - However, the difficulty in this lies in sorting the predictions' probabilities and converting these numerical predictions back to words within the functions where the _spacy similarity_ is used.\n",
    "\n",
    "__Future Improvements:__\n",
    "- A more precise method of identifying conflict labelled examples is needed. As noted in the Part 1 Evaluation section, predictive performance would likely be improved by incorporating a more detailed part of speech (POS) and sentence structure understaning for determining the appropriate input features for the Logistic Regression models.\n",
    "- Another thing to consider is that language is sequential. By developing an approach that considers the sequential nature of language (e.g., RNNs), predictive performance may be improved.\n",
    "- There are also other alternative approaches worth investigating. For example, a Latent Dirichlect Allocation (LDA) approach to identifying the various categories in a review may be an effective method that has not been considered in this ABSA implementation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16 ('nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5417c8c9055c1fa8caa20bdcdcb9a94277d5725cf87b106d0a354dab992ca3fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
